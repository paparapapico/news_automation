# clean_news_automation.py - MoviePy ì™„ì „ ì œê±° ë²„ì „
from fastapi import FastAPI, Request, Depends, HTTPException, Response, UploadFile, File
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from fastapi.responses import HTMLResponse, JSONResponse, RedirectResponse, FileResponse
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from contextlib import asynccontextmanager
import hashlib
import secrets
import os
import sqlite3
from datetime import datetime, timedelta
import uvicorn
import json
from typing import Optional, Dict, Any, List
import requests
import asyncio
import logging
import jwt
import random
from pydantic import BaseModel
import aiohttp
from bs4 import BeautifulSoup
import feedparser
import re
from urllib.parse import urlparse, urljoin
import time
from PIL import Image, ImageDraw, ImageFont, ImageFilter
import tempfile
import urllib.parse
import subprocess
import cv2
import numpy as np
import shutil

# TTS ì²˜ë¦¬ (ì•ˆì „í•˜ê²Œ)
try:
    import gtts
    TTS_AVAILABLE = True
    logger.info("âœ… gTTS ì‚¬ìš© ê°€ëŠ¥")
except ImportError:
    TTS_AVAILABLE = False
    logging.warning("âš ï¸ gTTS ì—†ìŒ - TTS ê¸°ëŠ¥ ë¹„í™œì„±í™”")

from io import BytesIO
import base64

# ===== ë¡œê¹… ì„¤ì • =====
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ===== í™˜ê²½ë³€ìˆ˜ ë¡œë“œ =====
try:
    from dotenv import load_dotenv
    load_dotenv()
    logger.info("âœ… í™˜ê²½ë³€ìˆ˜ ë¡œë“œ ì™„ë£Œ")
except ImportError:
    logger.warning("âš ï¸ dotenv ì—†ìŒ - í™˜ê²½ë³€ìˆ˜ë¥¼ ì§ì ‘ ì„¤ì •í•˜ì„¸ìš”")
except Exception as e:
    logger.warning(f"âš ï¸ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ ì˜¤ë¥˜: {e}")

# ===== í™˜ê²½ ê°ì§€ ë° í¬íŠ¸ ì„¤ì • =====
def get_safe_port():
    """ì•ˆì „í•œ í¬íŠ¸ ê°€ì ¸ì˜¤ê¸°"""
    try:
        port_env = os.environ.get("PORT")
        if port_env:
            port = int(port_env)
            logger.info(f"ğŸŒ Railway PORT í™˜ê²½ë³€ìˆ˜: {port}")
            return port
        else:
            logger.info("ğŸŒ ê¸°ë³¸ í¬íŠ¸ 8000 ì‚¬ìš©")
            return 8000
    except (ValueError, TypeError) as e:
        logger.error(f"âŒ í¬íŠ¸ íŒŒì‹± ì˜¤ë¥˜: {e}, ê¸°ë³¸ê°’ 8000 ì‚¬ìš©")
        return 8000

ENVIRONMENT = os.getenv('ENVIRONMENT', 'development')
IS_RENDER = bool(os.getenv('RENDER'))
IS_RAILWAY = bool(os.getenv('RAILWAY') or os.getenv('RAILWAY_ENVIRONMENT_NAME'))
IS_PRODUCTION = ENVIRONMENT == 'production' or IS_RENDER or IS_RAILWAY

if IS_RAILWAY:
    logger.info("ğŸš‚ Railway í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘")
elif IS_RENDER:
    logger.info("ğŸŒ Render í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘")
else:
    logger.info("ğŸ’» ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘")

# ===== ê¸°ë³¸ ì„¤ì • =====
DEBUG = os.getenv('DEBUG', 'True').lower() == 'true' and not IS_PRODUCTION
HOST = "0.0.0.0" if (IS_RAILWAY or IS_RENDER) else "127.0.0.1"
PORT = get_safe_port()

logger.info(f"ğŸŒ í˜¸ìŠ¤íŠ¸: {HOST}, í¬íŠ¸: {PORT}")

# íŒŒì¼ ê²½ë¡œ ì„¤ì •
UPLOAD_DIR = "uploads"
VIDEO_OUTPUT_DIR = "generated_videos"
AUDIO_OUTPUT_DIR = "generated_audio"
TEMP_DIR = "temp"

# ë””ë ‰í† ë¦¬ ìƒì„±
for directory in [UPLOAD_DIR, VIDEO_OUTPUT_DIR, AUDIO_OUTPUT_DIR, TEMP_DIR]:
    try:
        os.makedirs(directory, exist_ok=True)
        logger.info(f"âœ… ë””ë ‰í† ë¦¬ ìƒì„±/í™•ì¸: {directory}")
    except Exception as e:
        logger.warning(f"âš ï¸ ë””ë ‰í† ë¦¬ ìƒì„± ì‹¤íŒ¨: {directory} - {e}")

# JWT ì„¤ì •
JWT_SECRET = os.getenv('JWT_SECRET', 'your-secret-key-change-this-in-production')
JWT_ALGORITHM = "HS256"
JWT_EXPIRATION_HOURS = 24

# ë³´ì•ˆ ì„¤ì •
security = HTTPBearer(auto_error=False)

# OpenAI ê°€ì ¸ì˜¤ê¸°
try:
    import openai
    openai_version = openai.__version__
    logger.info(f"ğŸ“¦ OpenAI ë²„ì „: {openai_version}")
    
    if openai_version.startswith('1.'):
        OPENAI_V1 = True
    else:
        OPENAI_V1 = False
        
except ImportError:
    logger.warning("âŒ OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    OPENAI_V1 = False

# MoviePy ì™„ì „ ì œê±° - ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
MOVIEPY_AVAILABLE = False
logger.info("ğŸ¬ MoviePy ì œê±°ë¨ - OpenCVë¡œ ë¹„ë””ì˜¤ ì²˜ë¦¬")

# ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ ì„¤ì •
NEWS_CATEGORIES = {
    "stock": {
        "name": "ì£¼ì‹Â·ê²½ì œ",
        "keywords": ["ì£¼ì‹", "ì¦ì‹œ", "ì½”ìŠ¤í”¼", "ë‚˜ìŠ¤ë‹¥", "ì‚¼ì„±ì „ì", "ê²½ì œ", "ê¸ˆë¦¬", "í™˜ìœ¨", "ë¹„íŠ¸ì½”ì¸", "ì•”í˜¸í™”í"],
        "search_terms": ["stock market", "nasdaq", "kospi", "economy", "finance", "bitcoin", "cryptocurrency"],
        "trending_terms": ["ê¸‰ë“±", "í­ë½", "ìƒí•œê°€", "í•˜í•œê°€", "ì‚¬ìƒìµœê³ ê°€", "ê¸‰ë½"]
    },
    "politics": {
        "name": "ì •ì¹˜",
        "keywords": ["ëŒ€í†µë ¹", "êµ­íšŒ", "ì •ì¹˜", "ì„ ê±°", "ì •ë¶€", "ì—¬ì•¼", "ì •ì¹˜ì¸", "êµ­ì •ê°ì‚¬"],
        "search_terms": ["politics", "president", "government", "election", "korea politics"],
        "trending_terms": ["ê¸´ê¸‰", "ì†ë³´", "ë…¼ë€", "ë°œì–¸", "íšŒê²¬"]
    },
    "international": {
        "name": "í•´ì™¸ ì´ìŠˆ",
        "keywords": ["ë¯¸êµ­", "ì¤‘êµ­", "ì¼ë³¸", "ì „ìŸ", "êµ­ì œ", "ì™¸êµ", "íŠ¸ëŸ¼í”„", "ë°”ì´ë“ "],
        "search_terms": ["international", "world news", "global", "foreign", "trump", "biden"],
        "trending_terms": ["ì¶©ê²©", "ê¸´ê¸‰", "ì†ë³´", "ì „ìŸ", "ê°ˆë“±"]
    },
    "domestic": {
        "name": "êµ­ë‚´ ì´ìŠˆ",
        "keywords": ["ì‚¬ê±´", "ì‚¬ê³ ", "ì‚¬íšŒ", "ì´ìŠˆ", "ë…¼ë€", "ì—°ì˜ˆì¸", "ìŠ¤í¬ì¸ "],
        "search_terms": ["korea news", "domestic", "social issue", "korean society"],
        "trending_terms": ["ì¶©ê²©", "ë…¼ë€", "ì‚¬ê±´", "ë°œìƒ", "ì²´í¬"]
    },
    "technology": {
        "name": "ê¸°ìˆ Â·IT",
        "keywords": ["AI", "ì¸ê³µì§€ëŠ¥", "ê¸°ìˆ ", "IT", "ìŠ¤ë§ˆíŠ¸í°", "ë©”íƒ€ë²„ìŠ¤", "ì• í”Œ", "ì‚¼ì„±", "í…ŒìŠ¬ë¼"],
        "search_terms": ["technology", "AI", "tech news", "innovation", "apple", "samsung"],
        "trending_terms": ["í˜ì‹ ", "ì¶œì‹œ", "ê³µê°œ", "ë°œí‘œ", "ì‹ ì œí’ˆ"]
    },
    "entertainment": {
        "name": "ì—°ì˜ˆÂ·ìŠ¤í¬ì¸ ",
        "keywords": ["ì—°ì˜ˆì¸", "ì•„ì´ëŒ", "ë“œë¼ë§ˆ", "ì˜í™”", "ìŠ¤í¬ì¸ ", "ì¶•êµ¬", "ì•¼êµ¬", "KíŒ"],
        "search_terms": ["kpop", "korean drama", "entertainment", "sports", "celebrity"],
        "trending_terms": ["ë°ë·”", "ì»´ë°±", "ì—´ì• ", "ê²°í˜¼", "ìŠ¹ë¦¬"]
    }
}

# ìš”ì²­ ëª¨ë¸ë“¤
class NewsRequest(BaseModel):
    category: str
    max_articles: int = 5
    language: str = "ko"
    auto_post: bool = False

class ReelsRequest(BaseModel):
    news_id: int
    video_style: str = "trending"
    duration: int = 15
    voice_speed: float = 1.2
    include_captions: bool = True
    background_music: bool = True

class NewsPostRequest(BaseModel):
    news_id: int
    caption_style: str = "viral"
    include_hashtags: bool = True
    scheduled_time: Optional[str] = None

class MultiImagePostRequest(BaseModel):
    caption: str
    selected_images: List[str]
    hashtags: List[str]

# ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œìŠ¤í…œ
class AdvancedNewsScrapingSystem:
    def __init__(self):
        self.session = None
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
    
    async def _get_session(self):
        """aiohttp ì„¸ì…˜ lazy ì´ˆê¸°í™”"""
        try:
            if self.session is None or self.session.closed:
                connector = aiohttp.TCPConnector(ssl=False, limit=100, limit_per_host=30)
                timeout = aiohttp.ClientTimeout(total=30, connect=10)
                self.session = aiohttp.ClientSession(
                    connector=connector, 
                    timeout=timeout,
                    headers=self.headers
                )
        except Exception as e:
            logger.error(f"âŒ aiohttp ì„¸ì…˜ ìƒì„± ì˜¤ë¥˜: {e}")
            self.session = None
        return self.session
    
    def _generate_title_hash(self, title: str) -> str:
        """ì œëª© í•´ì‹œ ìƒì„±"""
        try:
            cleaned_title = re.sub(r'[^\w\s]', '', title.lower())
            cleaned_title = re.sub(r'\s+', ' ', cleaned_title).strip()
            return hashlib.md5(cleaned_title.encode('utf-8')).hexdigest()
        except Exception as e:
            logger.error(f"í•´ì‹œ ìƒì„± ì˜¤ë¥˜: {e}")
            return hashlib.md5(title.encode('utf-8', errors='ignore')).hexdigest()
    
    def _is_duplicate_news(self, title: str, category: str) -> bool:
        """ì¤‘ë³µ ë‰´ìŠ¤ ê²€ì‚¬"""
        try:
            title_hash = self._generate_title_hash(title)
            
            conn = sqlite3.connect("news_automation.db")
            cursor = conn.cursor()
            
            cursor.execute("""
                SELECT COUNT(*) FROM news_articles 
                WHERE title_hash = ? AND category = ? 
                AND datetime(scraped_at) > datetime('now', '-6 hours')
            """, (title_hash, category))
            
            count = cursor.fetchone()[0]
            conn.close()
            
            return count > 0
            
        except Exception as e:
            logger.error(f"ì¤‘ë³µ ê²€ì‚¬ ì˜¤ë¥˜: {e}")
            return False
    
    async def scrape_latest_news(self, category: str, max_articles: int = 10) -> List[Dict]:
        """ìµœì‹  ë‰´ìŠ¤ í¬ë¡¤ë§"""
        try:
            logger.info(f"ğŸ” {category} ì¹´í…Œê³ ë¦¬ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘")
            all_news = []
            
            # Google News í¬ë¡¤ë§
            google_news = await self._scrape_google_news(category, max_articles)
            logger.info(f"ğŸ“° Google Newsì—ì„œ {len(google_news)}ê°œ ë‰´ìŠ¤ ìˆ˜ì§‘")
            all_news.extend(google_news)
            
            if not all_news:
                logger.warning(f"âŒ {category}: ì›ë³¸ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨")
                return self._create_dummy_news(category, max_articles)
            
            # ì¤‘ë³µ ì œê±°
            unique_news = self._filter_duplicate_news(all_news, relaxed=True)
            logger.info(f"ğŸ”„ ì¤‘ë³µ ì œê±° í›„: {len(unique_news)}ê°œ")
            
            if not unique_news:
                logger.warning(f"âš ï¸ {category}: ì¤‘ë³µ ì œê±° í›„ ë‰´ìŠ¤ ì—†ìŒ")
                if all_news:
                    return all_news[:max_articles]
                else:
                    return self._create_dummy_news(category, max_articles)
            
            # ë°”ì´ëŸ´ ì ìˆ˜ ê¸°ë°˜ ì •ë ¬
            sorted_news = sorted(unique_news, key=lambda x: x['viral_score'], reverse=True)
            
            result = sorted_news[:max_articles]
            logger.info(f"âœ… {category}: ìµœì¢… {len(result)}ê°œ ë‰´ìŠ¤ ë°˜í™˜")
            return result
            
        except Exception as e:
            logger.error(f"âŒ ë‰´ìŠ¤ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
            return self._create_dummy_news(category, max_articles)
    
    def _create_dummy_news(self, category: str, max_articles: int) -> List[Dict]:
        """í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ë‰´ìŠ¤ ìƒì„±"""
        logger.info(f"ğŸ¤– {category} ì¹´í…Œê³ ë¦¬ ë”ë¯¸ ë‰´ìŠ¤ ìƒì„±")
        
        category_info = NEWS_CATEGORIES.get(category, NEWS_CATEGORIES["technology"])
        dummy_titles = {
            "technology": [
                "AI ê¸°ìˆ ì˜ ë†€ë¼ìš´ ë°œì „, ìƒˆë¡œìš´ í˜ì‹  ë“±ì¥",
                "ìŠ¤ë§ˆíŠ¸í° ì‹œì¥ì— ì¶©ê²©ì ì¸ ë³€í™” ì˜ˆê³ ",
                "í…Œí¬ ê¸°ì—…ë“¤ì˜ ìµœì‹  ë™í–¥ê³¼ ì „ë§"
            ],
            "stock": [
                "ì£¼ì‹ì‹œì¥ ê¸‰ë“±, íˆ¬ììë“¤ ì£¼ëª©",
                "ê²½ì œ ì „ë¬¸ê°€ë“¤ì´ ì˜ˆì¸¡í•˜ëŠ” ì‹œì¥ ë™í–¥",
                "ì½”ìŠ¤í”¼ ìƒìŠ¹ì„¸, ì£¼ìš” ì¢…ëª© ë¶„ì„"
            ],
            "domestic": [
                "êµ­ë‚´ ì£¼ìš” ì´ìŠˆ ì†ë³´ ì „í•´ì ¸",
                "ì‚¬íšŒ ì „ë°˜ì— ê±¸ì¹œ ìƒˆë¡œìš´ ë³€í™”",
                "êµ­ë¯¼ë“¤ì´ ê´€ì‹¬ ê°–ëŠ” ìµœì‹  ì†Œì‹"
            ]
        }
        
        titles = dummy_titles.get(category, ["ìµœì‹  ë‰´ìŠ¤ ì†ë³´", "ì£¼ìš” ì´ìŠˆ ì—…ë°ì´íŠ¸", "ì‚¬íšŒ ë™í–¥ ë¶„ì„"])
        
        dummy_news = []
        current_time = datetime.now().isoformat()
        
        for i in range(min(max_articles, len(titles))):
            title = f"{titles[i]} ({datetime.now().strftime('%H:%M')})"
            news_item = {
                "title": title,
                "title_hash": self._generate_title_hash(title),
                "link": f"https://example.com/news/{category}/{i+1}",
                "summary": f"{category_info['name']} ê´€ë ¨ ì¤‘ìš” ì†Œì‹ì…ë‹ˆë‹¤. {title}",
                "source": "ë‰´ìŠ¤ ìë™ ìƒì„±",
                "category": category,
                "keywords": category_info["keywords"],
                "viral_score": round(2.0 + i * 0.5, 2),
                "scraped_at": current_time
            }
            dummy_news.append(news_item)
        
        logger.info(f"âœ… {len(dummy_news)}ê°œ ë”ë¯¸ ë‰´ìŠ¤ ìƒì„± ì™„ë£Œ")
        return dummy_news
    
    async def _scrape_google_news(self, category: str, max_articles: int) -> List[Dict]:
        """Google News RSS í¬ë¡¤ë§"""
        try:
            category_info = NEWS_CATEGORIES.get(category, NEWS_CATEGORIES["domestic"])
            news_list = []
            
            session = await self._get_session()
            if session is None:
                logger.error("âŒ HTTP ì„¸ì…˜ ìƒì„± ì‹¤íŒ¨")
                return []
            
            search_terms = category_info["search_terms"][:2]
            
            for search_term in search_terms:
                try:
                    encoded_term = urllib.parse.quote(search_term)
                    rss_url = f"https://news.google.com/rss/search?q={encoded_term}&hl=ko&gl=KR&ceid=KR:ko"
                    
                    async with session.get(rss_url) as response:
                        if response.status == 200:
                            content = await response.text()
                            
                            if len(content) < 100:
                                continue
                            
                            feed = feedparser.parse(content)
                            
                            if not feed.entries:
                                continue
                            
                            for entry in feed.entries[:max_articles//2]:
                                try:
                                    title = entry.title
                                    if ' - ' in title:
                                        title = title.split(' - ')[0]
                                    
                                    news_item = {
                                        "title": title.strip(),
                                        "link": entry.link,
                                        "published": entry.get('published', ''),
                                        "summary": entry.get('summary', title),
                                        "source": "Google News",
                                        "category": category,
                                        "keywords": category_info["keywords"],
                                        "viral_score": self._calculate_viral_score(title),
                                        "scraped_at": datetime.now().isoformat()
                                    }
                                    news_list.append(news_item)
                                    
                                except Exception as entry_error:
                                    logger.warning(f"âš ï¸ ì—”íŠ¸ë¦¬ ì²˜ë¦¬ ì˜¤ë¥˜: {entry_error}")
                                    continue
                                    
                except Exception as term_error:
                    logger.warning(f"âš ï¸ ê²€ìƒ‰ì–´ '{search_term}' ì˜¤ë¥˜: {term_error}")
                    continue
            
            logger.info(f"ğŸ“Š ì´ ìˆ˜ì§‘ëœ ë‰´ìŠ¤: {len(news_list)}ê°œ")
            return news_list
            
        except Exception as e:
            logger.error(f"âŒ Google News í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
            return []
    
    def _filter_duplicate_news(self, news_list: List[Dict], relaxed: bool = False) -> List[Dict]:
        """ì¤‘ë³µ ë‰´ìŠ¤ í•„í„°ë§"""
        unique_news = []
        seen_hashes = set()
        
        for news in news_list:
            title_hash = self._generate_title_hash(news['title'])
            
            if title_hash in seen_hashes:
                continue
            
            if not relaxed and self._is_duplicate_news(news['title'], news['category']):
                continue
            
            seen_hashes.add(title_hash)
            news['title_hash'] = title_hash
            unique_news.append(news)
        
        return unique_news
    
    def _calculate_viral_score(self, title: str) -> float:
        """ë°”ì´ëŸ´ ì ìˆ˜ ê³„ì‚°"""
        score = 1.0
        title_lower = title.lower()
        
        viral_keywords = [
            "ê¸´ê¸‰", "ì†ë³´", "ì¶©ê²©", "ë…¼ë€", "í­ë“±", "í­ë½", "ê¸‰ë“±", "ê¸‰ë½", 
            "ì‚¬ìƒìµœê³ ", "ì‚¬ìƒìµœì €", "ì—­ëŒ€ìµœëŒ€", "íŒŒê²©", "ê¹œì§", "ë°˜ì „",
            "breaking", "urgent", "shock", "surge", "plunge", "exclusive"
        ]
        for keyword in viral_keywords:
            if keyword in title_lower:
                score += 2.0
        
        if re.search(r'\d+%|\d+ì–µ|\d+ë§Œ|\d+\$|\d+ë°°', title):
            score += 1.5
        
        if '?' in title or '!' in title:
            score += 1.0
        
        if 15 <= len(title) <= 60:
            score += 1.0
        
        return round(score, 2)
    
    async def close(self):
        """ì„¸ì…˜ ì¢…ë£Œ"""
        if self.session and not self.session.closed:
            await self.session.close()

# ë¦´ìŠ¤ ì œì‘ ì‹œìŠ¤í…œ - OpenCVë§Œ ì‚¬ìš©
class ReelsProductionSystem:
    def __init__(self):
        self.temp_dir = TEMP_DIR
        self.output_dir = VIDEO_OUTPUT_DIR
        self.audio_dir = AUDIO_OUTPUT_DIR
    
    async def create_news_reel(self, news_data: Dict, style: str = "trending", duration: int = 15) -> Dict:
        """ë‰´ìŠ¤ ë¦´ìŠ¤ ì œì‘ - OpenCV ì „ìš©"""
        try:
            logger.info(f"ğŸ“¹ ë¦´ìŠ¤ ì œì‘ ì‹œì‘: {news_data['title'][:50]}...")
            
            # TTS ìŒì„± ìƒì„± (ì„ íƒì )
            if TTS_AVAILABLE:
                audio_result = await self._generate_tts_audio(news_data, duration)
                if not audio_result["success"]:
                    logger.warning("âš ï¸ TTS ì‹¤íŒ¨, ìŒì„± ì—†ì´ ì§„í–‰")
            
            # ë¹„ì£¼ì–¼ ìƒì„± (OpenCV ì „ìš©)
            visual_result = await self._create_opencv_video(news_data, duration)
            
            return visual_result
            
        except Exception as e:
            logger.error(f"ë¦´ìŠ¤ ì œì‘ ì˜¤ë¥˜: {e}")
            return {
                "success": False,
                "error": str(e),
                "message": "ë¦´ìŠ¤ ì œì‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            }
    
    async def _generate_tts_audio(self, news_data: Dict, duration: int) -> Dict:
        """TTS ìŒì„± ìƒì„±"""
        try:
            if not TTS_AVAILABLE:
                return {"success": False, "error": "TTS ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ"}
            
            script = self._create_news_script(news_data, duration)
            tts = gtts.gTTS(text=script, lang='ko', slow=False)
            
            audio_filename = f"news_{news_data['id']}_{int(time.time())}.mp3"
            audio_path = os.path.join(self.audio_dir, audio_filename)
            
            tts.save(audio_path)
            logger.info(f"âœ… TTS ìŒì„± ìƒì„± ì™„ë£Œ: {audio_path}")
            
            return {
                "success": True,
                "audio_path": audio_path,
                "script": script
            }
            
        except Exception as e:
            logger.error(f"TTS ìƒì„± ì˜¤ë¥˜: {e}")
            return {"success": False, "error": str(e)}
    
    def _create_news_script(self, news_data: Dict, duration: int) -> str:
        """ë‰´ìŠ¤ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±"""
        title = news_data['title']
        category = NEWS_CATEGORIES.get(news_data['category'], {}).get('name', 'ë‰´ìŠ¤')
        
        if duration <= 15:
            script = f"{category} ì†ë³´ì…ë‹ˆë‹¤. {title}."
        else:
            script = f"{category} ë‰´ìŠ¤ë¥¼ ì „í•´ë“œë¦½ë‹ˆë‹¤. {title}."
        
        target_chars = int(duration * 2.5)
        if len(script) > target_chars:
            script = script[:target_chars-3] + "..."
        
        return script
    
    async def _create_opencv_video(self, news_data: Dict, duration: int) -> Dict:
        """OpenCVë¡œ ë¹„ë””ì˜¤ ìƒì„±"""
        try:
            # 9:16 ë¹„ìœ¨ (720x1280ìœ¼ë¡œ ê°€ë²¼ì›€)
            width, height = 720, 1280
            fps = 24  # ë” ê°€ë²¼ìš´ FPS
            frames_count = int(duration * fps)
            
            # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
            output_filename = f"reel_{news_data['id']}_{int(time.time())}.mp4"
            output_path = os.path.join(self.output_dir, output_filename)
            
            # VideoWriter ì„¤ì •
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
            
            if not out.isOpened():
                raise Exception("VideoWriter ì´ˆê¸°í™” ì‹¤íŒ¨")
            
            # í…ìŠ¤íŠ¸ ì¤€ë¹„
            title_text = news_data['title']
            if len(title_text) > 50:
                title_text = title_text[:47] + "..."
            
            logger.info(f"ğŸ¬ {frames_count}í”„ë ˆì„ ìƒì„± ì¤‘...")
            
            # í”„ë ˆì„ ìƒì„±
            for frame_num in range(frames_count):
                # ë°°ê²½ ìƒì„± (ë‹¨ìƒ‰)
                frame = np.zeros((height, width, 3), dtype=np.uint8)
                
                # ê·¸ë¼ë°ì´ì…˜ íš¨ê³¼
                for y in range(height):
                    ratio = y / height
                    color_val = int(50 + ratio * 100)
                    frame[y, :] = [color_val, color_val//2, 150]
                
                # í…ìŠ¤íŠ¸ ì¶”ê°€ (OpenCV ê¸°ë³¸ í°íŠ¸)
                text_lines = self._wrap_text(title_text, 25)
                
                for i, line in enumerate(text_lines[:3]):
                    y_pos = height//2 - 60 + i * 80
                    
                    # í…ìŠ¤íŠ¸ í¬ê¸° ì¡°ì •
                    font_scale = 1.5
                    thickness = 3
                    
                    # í…ìŠ¤íŠ¸ í¬ê¸° ê³„ì‚°
                    (text_width, text_height), baseline = cv2.getTextSize(
                        line, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness
                    )
                    
                    # ì¤‘ì•™ ì •ë ¬ x ì¢Œí‘œ
                    x_pos = (width - text_width) // 2
                    
                    # í…ìŠ¤íŠ¸ ê·¸ë¦¼ì
                    cv2.putText(frame, line, (x_pos + 3, y_pos + 3), 
                               cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 0, 0), thickness)
                    
                    # ë©”ì¸ í…ìŠ¤íŠ¸
                    cv2.putText(frame, line, (x_pos, y_pos), 
                               cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 255), thickness)
                
                # í”„ë ˆì„ ì“°ê¸°
                out.write(frame)
                
                # ì§„í–‰ë¥  ë¡œê·¸ (10% ë‹¨ìœ„)
                if frame_num % (frames_count // 10) == 0:
                    progress = (frame_num / frames_count) * 100
                    logger.info(f"ğŸ“¹ ì§„í–‰ë¥ : {progress:.0f}%")
            
            # VideoWriter í•´ì œ
            out.release()
            
            # íŒŒì¼ í¬ê¸° í™•ì¸
            if os.path.exists(output_path):
                file_size = os.path.getsize(output_path) / (1024 * 1024)  # MB
                logger.info(f"âœ… ë¦´ìŠ¤ ì œì‘ ì™„ë£Œ: {output_path} ({file_size:.1f}MB)")
                
                return {
                    "success": True,
                    "video_path": output_path,
                    "file_size_mb": round(file_size, 1),
                    "duration": duration,
                    "message": f"ë¦´ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì œì‘ë˜ì—ˆìŠµë‹ˆë‹¤! ({file_size:.1f}MB)"
                }
            else:
                raise Exception("ë¹„ë””ì˜¤ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            
        except Exception as e:
            logger.error(f"OpenCV ë¹„ë””ì˜¤ ìƒì„± ì˜¤ë¥˜: {e}")
            return {
                "success": False,
                "error": str(e),
                "message": "ë¹„ë””ì˜¤ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            }
    
    def _wrap_text(self, text: str, max_chars: int) -> List[str]:
        """í…ìŠ¤íŠ¸ë¥¼ ì—¬ëŸ¬ ì¤„ë¡œ ë¶„í• """
        words = text.split()
        lines = []
        current_line = ""
        
        for word in words:
            if len(current_line + " " + word) <= max_chars:
                current_line += " " + word if current_line else word
            else:
                if current_line:
                    lines.append(current_line)
                current_line = word
        
        if current_line:
            lines.append(current_line)
        
        return lines

# AI ì½˜í…ì¸  ìƒì„± ì‹œìŠ¤í…œ (ê¸°ì¡´ê³¼ ë™ì¼)
class AdvancedContentGenerator:
    def __init__(self):
        api_key = os.getenv('OPENAI_API_KEY')
        
        if not api_key:
            logger.warning("âš ï¸ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            self.openai_client = None
            return
        
        try:
            if OPENAI_V1:
                self.openai_client = openai.OpenAI(api_key=api_key)
            else:
                openai.api_key = api_key
                self.openai_client = openai
            
            logger.info(f"âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
            self.openai_client = None
    
    async def generate_viral_caption(self, news_data: Dict, style: str = "viral") -> Dict:
        """ë°”ì´ëŸ´ ìº¡ì…˜ ìƒì„±"""
        if not self.openai_client:
            return self._generate_fallback_caption(news_data)
        
        # OpenAI API ì‚¬ìš© ë¡œì§ (ê¸°ì¡´ê³¼ ë™ì¼)
        return self._generate_fallback_caption(news_data)
    
    def _generate_fallback_caption(self, news_data: Dict) -> Dict:
        """í´ë°± ìº¡ì…˜ ìƒì„±"""
        title = news_data['title']
        hooks = ["ğŸš¨ ê¸´ê¸‰ ì†ë³´!", "ğŸ˜± ì´ê±° ì‹¤í™”ì¸ê°€ìš”?", "ğŸ”¥ ì§€ê¸ˆ í™”ì œ!", "âš¡ ë°©ê¸ˆ í„°ì§„ ì†Œì‹!"]
        hook = random.choice(hooks)
        
        return {
            'caption': f"{hook}\n\n{title}\n\nì—¬ëŸ¬ë¶„ ìƒê°ì€? ğŸ‘‡",
            'style': 'viral'
        }

# Instagram ì„œë¹„ìŠ¤ í´ë˜ìŠ¤ (ê¸°ì¡´ê³¼ ë™ì¼í•˜ì§€ë§Œ ê°„ì†Œí™”)
class AdvancedInstagramService:
    def __init__(self):
        self.access_token = os.getenv('INSTAGRAM_ACCESS_TOKEN')
        self.business_account_id = os.getenv('INSTAGRAM_BUSINESS_ACCOUNT_ID')
        self.base_url = "https://graph.facebook.com"
        self.api_version = "v18.0"
        
    def validate_credentials(self) -> bool:
        return bool(self.access_token and self.business_account_id)
    
    async def test_connection(self) -> Dict:
        """Instagram ì—°ê²° í…ŒìŠ¤íŠ¸"""
        if not self.validate_credentials():
            return {
                "success": False,
                "error": "Instagram ì¸ì¦ ì •ë³´ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
            }
        
        return {
            "success": True,
            "message": "Instagram ì—°ê²° ì„¤ì • ì™„ë£Œ"
        }

# ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” (ê¸°ì¡´ê³¼ ë™ì¼)
def init_enhanced_db():
    """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
    try:
        conn = sqlite3.connect("news_automation.db")
        cursor = conn.cursor()
        
        # ë‰´ìŠ¤ í…Œì´ë¸”
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS news_articles (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                title TEXT NOT NULL,
                title_hash TEXT,
                link TEXT,
                summary TEXT,
                content TEXT,
                source TEXT,
                category TEXT,
                keywords TEXT,
                viral_score REAL,
                scraped_at TEXT,
                published_at TEXT,
                is_processed BOOLEAN DEFAULT FALSE,
                view_count INTEGER DEFAULT 0
            )
        """)
        
        # ë¦´ìŠ¤ í…Œì´ë¸”
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS news_reels (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                news_id INTEGER,
                video_path TEXT,
                audio_path TEXT,
                script TEXT,
                style TEXT,
                duration INTEGER,
                file_size_mb REAL,
                created_at TEXT,
                status TEXT DEFAULT 'created',
                view_count INTEGER DEFAULT 0,
                like_count INTEGER DEFAULT 0,
                FOREIGN KEY (news_id) REFERENCES news_articles (id)
            )
        """)
        
        conn.commit()
        conn.close()
        logger.info("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
        return True
    except Exception as e:
        logger.error(f"âŒ DB ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
        return False

# FastAPI ì•± ì´ˆê¸°í™”
@asynccontextmanager
async def lifespan(app: FastAPI):
    logger.info("ğŸš€ ADVANCED NEWS AUTOMATION ì‹œì‘ (MoviePy ì œê±°)")
    
    try:
        init_enhanced_db()
    except Exception as e:
        logger.error(f"DB ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    yield

app = FastAPI(
    title="ADVANCED NEWS AUTOMATION", 
    description="AI ë‰´ìŠ¤ ìˆ˜ì§‘ + OpenCV ë¦´ìŠ¤ ì œì‘",
    version="2.1.0",
    lifespan=lifespan, 
    debug=DEBUG
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì •ì  íŒŒì¼ ì„œë¹™
try:
    app.mount("/generated_videos", StaticFiles(directory=VIDEO_OUTPUT_DIR), name="videos")
    logger.info("âœ… ì •ì  íŒŒì¼ ë§ˆìš´íŠ¸ ì™„ë£Œ")
except Exception as e:
    logger.warning(f"âš ï¸ ì •ì  íŒŒì¼ ë§ˆìš´íŠ¸ ì‹¤íŒ¨: {e}")

@app.get("/favicon.ico", include_in_schema=False)
async def favicon():
    return Response(status_code=204)

# ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
_news_scraper = None
_content_generator = None
_instagram_service = None
_reels_producer = None

def get_news_scraper():
    global _news_scraper
    if _news_scraper is None:
        _news_scraper = AdvancedNewsScrapingSystem()
    return _news_scraper

def get_content_generator():
    global _content_generator
    if _content_generator is None:
        _content_generator = AdvancedContentGenerator()
    return _content_generator

def get_instagram_service():
    global _instagram_service
    if _instagram_service is None:
        _instagram_service = AdvancedInstagramService()
    return _instagram_service

def get_reels_producer():
    global _reels_producer
    if _reels_producer is None:
        _reels_producer = ReelsProductionSystem()
    return _reels_producer

# API ë¼ìš°íŠ¸ë“¤

@app.get("/")
async def home():
    """í™ˆí˜ì´ì§€"""
    return {
        "title": "ğŸ¬ ADVANCED NEWS AUTOMATION",
        "description": "AI ë‰´ìŠ¤ ìˆ˜ì§‘ + OpenCV ë¦´ìŠ¤ ì œì‘",
        "environment": f"{'Railway' if IS_RAILWAY else 'Render' if IS_RENDER else 'Local'}",
        "features": [
            "ğŸ” ë‰´ìŠ¤ ìˆ˜ì§‘ (Google News)",
            "ğŸ¬ OpenCV ë¦´ìŠ¤ ì œì‘",
            "ğŸš« MoviePy ì œê±° (ì•ˆì •ì„± í–¥ìƒ)"
        ],
        "status": "MoviePy ì˜¤ë¥˜ í•´ê²°ë¨"
    }

@app.get("/health")
async def health_check():
    """ê°„ë‹¨í•˜ê³  ë¹ ë¥¸ í—¬ìŠ¤ì²´í¬ - Railway ìµœì í™”"""
    try:
        # ì¦‰ì‹œ ì‘ë‹µ (DB ì²´í¬ ì—†ì´)
        return {
            "status": "healthy",
            "timestamp": datetime.now().isoformat(),
            "environment": "Railway" if IS_RAILWAY else "Local",
            "port": PORT,
            "message": "OK"
        }
    except Exception as e:
        # ì˜¤ë¥˜ê°€ ìˆì–´ë„ 200 ì‘ë‹µ
        return {
            "status": "warning",
            "timestamp": datetime.now().isoformat(),
            "error": str(e),
            "message": "OK"
        }

@app.get("/dashboard", response_class=HTMLResponse)
async def dashboard():
    """ëŒ€ì‹œë³´ë“œ í˜ì´ì§€"""
    env_name = "Railway" if IS_RAILWAY else "Render" if IS_RENDER else "Local"
    return f"""
<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ğŸ¬ NEWS AUTOMATION - {env_name}</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet">
    <style>
        body {{
            background: linear-gradient(135deg, #6366f1 0%, #8b5cf6 100%);
            font-family: -apple-system, BlinkMacSystemFont, sans-serif;
            min-height: 100vh;
        }}
        .container {{
            background: rgba(255, 255, 255, 0.95);
            backdrop-filter: blur(10px);
            border-radius: 20px;
            margin-top: 20px;
            padding: 40px;
        }}
        .success-card {{
            background: linear-gradient(135deg, #10b981, #06b6d4);
            color: white;
            border-radius: 15px;
            padding: 30px;
            text-align: center;
        }}
    </style>
</head>
<body>
    <div class="container">
        <div class="text-center mb-5">
            <h1 class="display-4 fw-bold">
                ğŸ¬ NEWS AUTOMATION - {env_name}
            </h1>
            <p class="lead">MoviePy ì˜¤ë¥˜ ì™„ì „ í•´ê²°!</p>
        </div>

        <div class="success-card">
            <h3>âœ… MoviePy ì˜¤ë¥˜ í•´ê²° ì™„ë£Œ!</h3>
            <p class="mb-4">OpenCV ì „ìš©ìœ¼ë¡œ ì „í™˜í•˜ì—¬ ëª¨ë“  ì˜ì¡´ì„± ë¬¸ì œë¥¼ í•´ê²°í–ˆìŠµë‹ˆë‹¤.</p>
            
            <div class="row text-center">
                <div class="col-md-4">
                    <h5>ğŸš« ì œê±°ë¨</h5>
                    <small>MoviePy, FFmpeg</small>
                </div>
                <div class="col-md-4">
                    <h5>âœ… ì‚¬ìš© ì¤‘</h5>
                    <small>OpenCV, Pillow</small>
                </div>
                <div class="col-md-4">
                    <h5>ğŸ¯ ê²°ê³¼</h5>
                    <small>HTTP 502 ì˜¤ë¥˜ í•´ê²°</small>
                </div>
            </div>
            
            <div class="mt-4">
                <a href="/docs" class="btn btn-light me-3">API ë¬¸ì„œ</a>
                <button class="btn btn-outline-light" onclick="location.reload()">ìƒˆë¡œê³ ì¹¨</button>
            </div>
        </div>
    </div>
</body>
</html>
    """

@app.post("/api/scrape-news")
async def scrape_news_api(request: NewsRequest):
    """ë‰´ìŠ¤ ìˆ˜ì§‘ API"""
    try:
        logger.info(f"ğŸ“° ë‰´ìŠ¤ ìˆ˜ì§‘ ìš”ì²­: {request.category}")
        
        scraper = get_news_scraper()
        news_list = await scraper.scrape_latest_news(request.category, request.max_articles)
        
        if not news_list:
            return {
                "success": False, 
                "message": "ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤"
            }
        
        # DBì— ì €ì¥
        saved_news = []
        try:
            conn = sqlite3.connect("news_automation.db")
            cursor = conn.cursor()
            
            for news in news_list:
                cursor.execute("""
                    INSERT INTO news_articles 
                    (title, title_hash, link, summary, source, category, keywords, viral_score, scraped_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    news['title'],
                    news['title_hash'],
                    news['link'],
                    news['summary'],
                    news['source'],
                    news['category'],
                    json.dumps(news['keywords']),
                    news['viral_score'],
                    news['scraped_at']
                ))
                
                news_id = cursor.lastrowid
                news['id'] = news_id
                saved_news.append(news)
            
            conn.commit()
            conn.close()
            
        except Exception as db_error:
            logger.error(f"âŒ DB ì €ì¥ ì˜¤ë¥˜: {db_error}")
        
        return {
            "success": True,
            "message": f"{len(saved_news)}ê°œì˜ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤",
            "news": saved_news
        }
        
    except Exception as e:
        logger.error(f"âŒ ë‰´ìŠ¤ ìˆ˜ì§‘ API ì˜¤ë¥˜: {e}")
        return {
            "success": False, 
            "error": str(e), 
            "message": "ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤"
        }

if __name__ == "__main__":
    env_name = "Railway" if IS_RAILWAY else "Render" if IS_RENDER else "Local"
    print(f"ğŸš€ NEWS AUTOMATION ì‹œì‘ ({env_name})")
    print("ğŸ¯ MoviePy ì™„ì „ ì œê±° - HTTP 502 ì˜¤ë¥˜ í•´ê²°!")
    print(f"ğŸ“± ëŒ€ì‹œë³´ë“œ: http://{HOST}:{PORT}/dashboard")
    
    if not (IS_RAILWAY or IS_RENDER):
        uvicorn.run(app, host=HOST, port=PORT, reload=DEBUG)
    else:
        print(f"{env_name} í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘...")