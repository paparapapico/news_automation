# clean_news_automation.py - ê°œì„ ëœ ë‰´ìŠ¤ & ë¦´ìŠ¤ ìë™í™” ë°±ì—”ë“œ
from fastapi import FastAPI, Request, Depends, HTTPException, Response, UploadFile, File
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from fastapi.responses import HTMLResponse, JSONResponse, RedirectResponse, FileResponse
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from contextlib import asynccontextmanager
import hashlib
import secrets
import os
import sqlite3
from datetime import datetime, timedelta
import uvicorn
import json
from typing import Optional, Dict, Any, List
import requests
import asyncio
import logging
import jwt
import random
from pydantic import BaseModel
import aiohttp
from bs4 import BeautifulSoup
import feedparser
import re
from urllib.parse import urlparse, urljoin
import time
from PIL import Image, ImageDraw, ImageFont, ImageFilter
import tempfile
import urllib.parse
import subprocess
import cv2
import numpy as np
from moviepy.editor import VideoFileClip, AudioFileClip, TextClip, CompositeVideoClip, concatenate_videoclips
import gtts
from io import BytesIO
import base64
import shutil



# OpenAI ê°€ì ¸ì˜¤ê¸°
try:
    import openai
    openai_version = openai.__version__
    print(f"ğŸ“¦ OpenAI ë²„ì „: {openai_version}")
    
    if openai_version.startswith('1.'):
        OPENAI_V1 = True
    else:
        OPENAI_V1 = False
        
except ImportError:
    print("âŒ OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    OPENAI_V1 = False

logger = logging.getLogger(__name__)

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
try:
    from dotenv import load_dotenv
    load_dotenv()
    print("âœ… í™˜ê²½ë³€ìˆ˜ ë¡œë“œ ì™„ë£Œ")
except:
    print("âš ï¸ dotenv ì—†ìŒ - í™˜ê²½ë³€ìˆ˜ë¥¼ ì§ì ‘ ì„¤ì •í•˜ì„¸ìš”")

# ì„¤ì •
DEBUG = os.getenv('DEBUG', 'True').lower() == 'true'
HOST = os.getenv('HOST', '127.0.0.1')
PORT = int(os.getenv('PORT', 8000))

# íŒŒì¼ ê²½ë¡œ ì„¤ì •
UPLOAD_DIR = "uploads"
VIDEO_OUTPUT_DIR = "generated_videos"
AUDIO_OUTPUT_DIR = "generated_audio"
TEMP_DIR = "temp"

# ë””ë ‰í† ë¦¬ ìƒì„±
for directory in [UPLOAD_DIR, VIDEO_OUTPUT_DIR, AUDIO_OUTPUT_DIR, TEMP_DIR]:
    os.makedirs(directory, exist_ok=True)

# JWT ì„¤ì •
JWT_SECRET = os.getenv('JWT_SECRET', 'your-secret-key-change-this-in-production')
JWT_ALGORITHM = "HS256"
JWT_EXPIRATION_HOURS = 24

# ë³´ì•ˆ ì„¤ì •
security = HTTPBearer(auto_error=False)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ ì„¤ì • (í™•ì¥ë¨)
NEWS_CATEGORIES = {
    "stock": {
        "name": "ì£¼ì‹Â·ê²½ì œ",
        "keywords": ["ì£¼ì‹", "ì¦ì‹œ", "ì½”ìŠ¤í”¼", "ë‚˜ìŠ¤ë‹¥", "ì‚¼ì„±ì „ì", "ê²½ì œ", "ê¸ˆë¦¬", "í™˜ìœ¨", "ë¹„íŠ¸ì½”ì¸", "ì•”í˜¸í™”í"],
        "search_terms": ["stock market", "nasdaq", "kospi", "economy", "finance", "bitcoin", "cryptocurrency"],
        "trending_terms": ["ê¸‰ë“±", "í­ë½", "ìƒí•œê°€", "í•˜í•œê°€", "ì‚¬ìƒìµœê³ ê°€", "ê¸‰ë½"]
    },
    "politics": {
        "name": "ì •ì¹˜",
        "keywords": ["ëŒ€í†µë ¹", "êµ­íšŒ", "ì •ì¹˜", "ì„ ê±°", "ì •ë¶€", "ì—¬ì•¼", "ì •ì¹˜ì¸", "êµ­ì •ê°ì‚¬"],
        "search_terms": ["politics", "president", "government", "election", "korea politics"],
        "trending_terms": ["ê¸´ê¸‰", "ì†ë³´", "ë…¼ë€", "ë°œì–¸", "íšŒê²¬"]
    },
    "international": {
        "name": "í•´ì™¸ ì´ìŠˆ",
        "keywords": ["ë¯¸êµ­", "ì¤‘êµ­", "ì¼ë³¸", "ì „ìŸ", "êµ­ì œ", "ì™¸êµ", "íŠ¸ëŸ¼í”„", "ë°”ì´ë“ "],
        "search_terms": ["international", "world news", "global", "foreign", "trump", "biden"],
        "trending_terms": ["ì¶©ê²©", "ê¸´ê¸‰", "ì†ë³´", "ì „ìŸ", "ê°ˆë“±"]
    },
    "domestic": {
        "name": "êµ­ë‚´ ì´ìŠˆ",
        "keywords": ["ì‚¬ê±´", "ì‚¬ê³ ", "ì‚¬íšŒ", "ì´ìŠˆ", "ë…¼ë€", "ì—°ì˜ˆì¸", "ìŠ¤í¬ì¸ "],
        "search_terms": ["korea news", "domestic", "social issue", "korean society"],
        "trending_terms": ["ì¶©ê²©", "ë…¼ë€", "ì‚¬ê±´", "ë°œìƒ", "ì²´í¬"]
    },
    "technology": {
        "name": "ê¸°ìˆ Â·IT",
        "keywords": ["AI", "ì¸ê³µì§€ëŠ¥", "ê¸°ìˆ ", "IT", "ìŠ¤ë§ˆíŠ¸í°", "ë©”íƒ€ë²„ìŠ¤", "ì• í”Œ", "ì‚¼ì„±", "í…ŒìŠ¬ë¼"],
        "search_terms": ["technology", "AI", "tech news", "innovation", "apple", "samsung"],
        "trending_terms": ["í˜ì‹ ", "ì¶œì‹œ", "ê³µê°œ", "ë°œí‘œ", "ì‹ ì œí’ˆ"]
    },
    "entertainment": {
        "name": "ì—°ì˜ˆÂ·ìŠ¤í¬ì¸ ",
        "keywords": ["ì—°ì˜ˆì¸", "ì•„ì´ëŒ", "ë“œë¼ë§ˆ", "ì˜í™”", "ìŠ¤í¬ì¸ ", "ì¶•êµ¬", "ì•¼êµ¬", "KíŒ"],
        "search_terms": ["kpop", "korean drama", "entertainment", "sports", "celebrity"],
        "trending_terms": ["ë°ë·”", "ì»´ë°±", "ì—´ì• ", "ê²°í˜¼", "ìŠ¹ë¦¬"]
    }
}

# ìš”ì²­ ëª¨ë¸ë“¤
class NewsRequest(BaseModel):
    category: str
    max_articles: int = 5
    language: str = "ko"
    auto_post: bool = False

class ReelsRequest(BaseModel):
    news_id: int
    video_style: str = "trending"  # trending, news, minimal
    duration: int = 15  # 15ì´ˆ (ì¸ìŠ¤íƒ€ê·¸ë¨ ì•Œê³ ë¦¬ì¦˜ ìµœì í™”)
    voice_speed: float = 1.2
    include_captions: bool = True
    background_music: bool = True

class NewsPostRequest(BaseModel):
    news_id: int
    caption_style: str = "viral"  # viral, engaging, informative
    include_hashtags: bool = True
    scheduled_time: Optional[str] = None

class MultiImagePostRequest(BaseModel):
    caption: str
    selected_images: List[str]
    hashtags: List[str]

# í–¥ìƒëœ ë‰´ìŠ¤ í¬ë¡¤ë§ ì‹œìŠ¤í…œ
class AdvancedNewsScrapingSystem:
    def __init__(self):
        self.session = None
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        # ë‹¤ì–‘í•œ ë‰´ìŠ¤ ì†ŒìŠ¤ ì¶”ê°€
        self.news_sources = {
            "google_news": {
                "url": "https://news.google.com/rss",
                "search_url": "https://news.google.com/search"
            },
            "naver_news": {
                "url": "https://news.naver.com/main/rss/read.nhn",
                "search_url": "https://search.naver.com/search.naver"
            },
            "daum_news": {
                "url": "https://media.daum.net/rss/",
                "search_url": "https://search.daum.net/search"
            }
        }
    
    async def _get_session(self):
        """aiohttp ì„¸ì…˜ lazy ì´ˆê¸°í™”"""
        if self.session is None or self.session.closed:
            self.session = aiohttp.ClientSession()
        return self.session
    
    def _generate_title_hash(self, title: str) -> str:
        """ì œëª© í•´ì‹œ ìƒì„± (ì¤‘ë³µ ê²€ì‚¬ìš©)"""
        # íŠ¹ìˆ˜ë¬¸ì ì œê±°í•˜ê³  ì†Œë¬¸ìë¡œ ë³€í™˜
        cleaned_title = re.sub(r'[^\w\s]', '', title.lower())
        # ê³µë°± ì •ê·œí™”
        cleaned_title = re.sub(r'\s+', ' ', cleaned_title).strip()
        # í•´ì‹œ ìƒì„±
        return hashlib.md5(cleaned_title.encode('utf-8')).hexdigest()
    
    def _is_duplicate_news(self, title: str, category: str) -> bool:
        """ì¤‘ë³µ ë‰´ìŠ¤ ê²€ì‚¬ (ìµœê·¼ 24ì‹œê°„)"""
        try:
            title_hash = self._generate_title_hash(title)
            
            conn = sqlite3.connect("news_automation.db")
            cursor = conn.cursor()
            
            # ê°™ì€ ì¹´í…Œê³ ë¦¬ì—ì„œ ê°™ì€ í•´ì‹œê°€ ìˆëŠ”ì§€ í™•ì¸ (ìµœê·¼ 24ì‹œê°„)
            cursor.execute("""
                SELECT COUNT(*) FROM news_articles 
                WHERE title_hash = ? AND category = ? 
                AND datetime(scraped_at) > datetime('now', '-1 days')
            """, (title_hash, category))
            
            count = cursor.fetchone()[0]
            conn.close()
            
            return count > 0
            
        except Exception as e:
            logger.error(f"ì¤‘ë³µ ê²€ì‚¬ ì˜¤ë¥˜: {e}")
            return False
    
    async def scrape_latest_news(self, category: str, max_articles: int = 10) -> List[Dict]:
        """ìµœì‹  ë‰´ìŠ¤ í¬ë¡¤ë§ (ë‹¤ì¤‘ ì†ŒìŠ¤)"""
        try:
            all_news = []
            
            # Google News í¬ë¡¤ë§
            google_news = await self._scrape_google_news(category, max_articles)
            all_news.extend(google_news)
            
            # ì¤‘ë³µ ì œê±°
            unique_news = self._filter_duplicate_news(all_news)
            
            # ë°”ì´ëŸ´ ì ìˆ˜ ê¸°ë°˜ ì •ë ¬
            sorted_news = sorted(unique_news, key=lambda x: x['viral_score'], reverse=True)
            
            return sorted_news[:max_articles]
            
        except Exception as e:
            logger.error(f"ë‰´ìŠ¤ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
            return []
    
    async def _scrape_google_news(self, category: str, max_articles: int) -> List[Dict]:
        """Google News RSS í¬ë¡¤ë§ (ê°œì„ )"""
        try:
            category_info = NEWS_CATEGORIES.get(category, NEWS_CATEGORIES["domestic"])
            news_list = []
            
            session = await self._get_session()
            
            # íŠ¸ë Œë”© í‚¤ì›Œë“œì™€ ì¼ë°˜ í‚¤ì›Œë“œ ê²°í•©
            all_terms = category_info["search_terms"] + category_info.get("trending_terms", [])
            
            for search_term in all_terms[:3]:
                try:
                    # URL ì¸ì½”ë”©
                    encoded_term = urllib.parse.quote(search_term)
                    rss_url = f"https://news.google.com/rss/search?q={encoded_term}&hl=ko&gl=KR&ceid=KR:ko"
                    
                    async with session.get(rss_url, headers=self.headers, timeout=15) as response:
                        if response.status == 200:
                            content = await response.text()
                            feed = feedparser.parse(content)
                            
                            for entry in feed.entries[:max_articles//3]:
                                # ì œëª© ì •ë¦¬
                                title = entry.title
                                if ' - ' in title:
                                    title = title.split(' - ')[0]
                                
                                news_item = {
                                    "title": title.strip(),
                                    "link": entry.link,
                                    "published": entry.get('published', ''),
                                    "summary": entry.get('summary', title),
                                    "source": "Google News",
                                    "category": category,
                                    "keywords": category_info["keywords"],
                                    "viral_score": self._calculate_viral_score(title),
                                    "scraped_at": datetime.now().isoformat()
                                }
                                news_list.append(news_item)
                                
                except Exception as e:
                    logger.warning(f"Google News ê²€ìƒ‰ì–´ '{search_term}' ì˜¤ë¥˜: {e}")
                    continue
            
            return news_list
            
        except Exception as e:
            logger.error(f"Google News í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
            return []
    
    def _filter_duplicate_news(self, news_list: List[Dict]) -> List[Dict]:
        """ì¤‘ë³µ ë‰´ìŠ¤ í•„í„°ë§"""
        unique_news = []
        seen_hashes = set()
        
        for news in news_list:
            title_hash = self._generate_title_hash(news['title'])
            
            # í˜„ì¬ ì„¸ì…˜ì—ì„œ ì¤‘ë³µ í™•ì¸
            if title_hash in seen_hashes:
                continue
            
            # DBì—ì„œ ì¤‘ë³µ í™•ì¸
            if self._is_duplicate_news(news['title'], news['category']):
                logger.info(f"ì¤‘ë³µ ë‰´ìŠ¤ ì œì™¸: {news['title'][:50]}...")
                continue
            
            seen_hashes.add(title_hash)
            news['title_hash'] = title_hash
            unique_news.append(news)
        
        logger.info(f"ì¤‘ë³µ ì œê±° ê²°ê³¼: {len(news_list)} â†’ {len(unique_news)}")
        return unique_news
    
    def _calculate_viral_score(self, title: str) -> float:
        """ë°”ì´ëŸ´ ì ìˆ˜ ê³„ì‚° (ì¸ìŠ¤íƒ€ê·¸ë¨ ì•Œê³ ë¦¬ì¦˜ ìµœì í™”)"""
        score = 1.0
        title_lower = title.lower()
        
        # ìê·¹ì ì¸ í‚¤ì›Œë“œ (ë†’ì€ ì ìˆ˜)
        viral_keywords = [
            "ê¸´ê¸‰", "ì†ë³´", "ì¶©ê²©", "ë…¼ë€", "í­ë“±", "í­ë½", "ê¸‰ë“±", "ê¸‰ë½", 
            "ì‚¬ìƒìµœê³ ", "ì‚¬ìƒìµœì €", "ì—­ëŒ€ìµœëŒ€", "íŒŒê²©", "ê¹œì§", "ë°˜ì „",
            "breaking", "urgent", "shock", "surge", "plunge", "exclusive",
            "ì²˜ìŒ", "ìµœì´ˆ", "ë“œë””ì–´", "ê²°êµ­", "ë§ˆì¹¨ë‚´", "ë†€ë¼ìš´"
        ]
        for keyword in viral_keywords:
            if keyword in title_lower:
                score += 3.0
        
        # ê°ì •ì„ ìê·¹í•˜ëŠ” í‚¤ì›Œë“œ
        emotion_keywords = [
            "ë¶„ë…¸", "ëˆˆë¬¼", "ê°ë™", "í™”ì œ", "ëŒ€ë°•", "ì‹¤í™”", "ë¯¿ì„ìˆ˜ì—†ëŠ”",
            "amazing", "incredible", "unbelievable", "shocking"
        ]
        for keyword in emotion_keywords:
            if keyword in title_lower:
                score += 2.5
        
        # ìˆ«ì/í¼ì„¼íŠ¸ í¬í•¨ ì‹œ ì ìˆ˜
        if re.search(r'\d+%|\d+ì–µ|\d+ë§Œ|\d+\$|\d+ë°°|\d+ë…„ë§Œì—', title):
            score += 2.0
        
        # ìœ ëª… ì¸ë¬¼/ë¸Œëœë“œ
        famous_entities = [
            "ì‚¼ì„±", "ì• í”Œ", "í…ŒìŠ¬ë¼", "ë¹„íŠ¸ì½”ì¸", "ëŒ€í†µë ¹", "trump", "biden",
            "bts", "ë¸”ë™í•‘í¬", "ì•„ì´ìœ ", "ì†í¥ë¯¼", "ì´ì¬ìš©"
        ]
        for entity in famous_entities:
            if entity in title_lower:
                score += 1.5
        
        # ì˜ë¬¸ë¬¸/ëŠë‚Œí‘œ
        if '?' in title or '!' in title:
            score += 1.0
        
        # ì œëª© ê¸¸ì´ ì ì ˆì„± (ì¸ìŠ¤íƒ€ê·¸ë¨ ìµœì í™”)
        if 15 <= len(title) <= 60:
            score += 1.5
        elif len(title) > 80:
            score -= 1.0
        
        return round(score, 2)
    
    async def close(self):
        """ì„¸ì…˜ ì¢…ë£Œ"""
        if self.session and not self.session.closed:
            await self.session.close()

# ë¦´ìŠ¤ ì œì‘ ì‹œìŠ¤í…œ
class ReelsProductionSystem:
    def __init__(self):
        self.temp_dir = TEMP_DIR
        self.output_dir = VIDEO_OUTPUT_DIR
        self.audio_dir = AUDIO_OUTPUT_DIR
        
        # í°íŠ¸ ì„¤ì • (Windows ê²½ë¡œ ì¶”ê°€)
        self.font_paths = {
            "bold": self._find_font(["NanumGothicBold.ttf", "malgun.ttf", "arial-bold.ttf", "DejaVuSans-Bold.ttf"]),
            "regular": self._find_font(["NanumGothic.ttf", "malgun.ttf", "arial.ttf", "DejaVuSans.ttf"])
        }
    
    def _find_font(self, font_names: List[str]) -> str:
        """ì‹œìŠ¤í…œì—ì„œ í°íŠ¸ ì°¾ê¸°"""
        font_paths = [
            "C:/Windows/Fonts/",  # Windows
            "/System/Library/Fonts/",  # macOS
            "/usr/share/fonts/",  # Linux
            "./fonts/",
            ""
        ]
        
        for font_name in font_names:
            for font_path in font_paths:
                full_path = os.path.join(font_path, font_name)
                if os.path.exists(full_path):
                    return full_path
        
        return None  # ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©
    
    async def create_news_reel(self, news_data: Dict, style: str = "trending", duration: int = 15) -> Dict:
        """ë‰´ìŠ¤ ë¦´ìŠ¤ ì œì‘"""
        try:
            logger.info(f"ğŸ“¹ ë¦´ìŠ¤ ì œì‘ ì‹œì‘: {news_data['title'][:50]}...")
            
            # 1ë‹¨ê³„: TTS ìŒì„± ìƒì„±
            audio_result = await self._generate_tts_audio(news_data, duration)
            if not audio_result["success"]:
                return audio_result
            
            # 2ë‹¨ê³„: ë¹„ì£¼ì–¼ ìƒì„±
            visual_result = await self._create_visual_content(news_data, style, duration)
            if not visual_result["success"]:
                return visual_result
            
            # 3ë‹¨ê³„: ìë§‰ ìƒì„±
            caption_result = await self._generate_captions(news_data)
            if not caption_result["success"]:
                return caption_result
            
            # 4ë‹¨ê³„: ìµœì¢… ë¹„ë””ì˜¤ í•©ì„±
            final_result = await self._compose_final_video(
                audio_result["audio_path"],
                visual_result["visual_path"],
                caption_result["captions"],
                news_data,
                style,
                duration
            )
            
            return final_result
            
        except Exception as e:
            logger.error(f"ë¦´ìŠ¤ ì œì‘ ì˜¤ë¥˜: {e}")
            return {
                "success": False,
                "error": str(e),
                "message": "ë¦´ìŠ¤ ì œì‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            }
    
    async def _generate_tts_audio(self, news_data: Dict, duration: int) -> Dict:
        """TTS ìŒì„± ìƒì„±"""
        try:
            # ë‰´ìŠ¤ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± (durationì— ë§ê²Œ ì¡°ì •)
            script = self._create_news_script(news_data, duration)
            
            # gTTSë¡œ ìŒì„± ìƒì„±
            tts = gtts.gTTS(text=script, lang='ko', slow=False)
            
            # ì„ì‹œ íŒŒì¼ì— ì €ì¥
            audio_filename = f"news_{news_data['id']}_{int(time.time())}.mp3"
            audio_path = os.path.join(self.audio_dir, audio_filename)
            
            tts.save(audio_path)
            
            logger.info(f"âœ… TTS ìŒì„± ìƒì„± ì™„ë£Œ: {audio_path}")
            
            return {
                "success": True,
                "audio_path": audio_path,
                "script": script,
                "duration": duration
            }
            
        except Exception as e:
            logger.error(f"TTS ìƒì„± ì˜¤ë¥˜: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    def _create_news_script(self, news_data: Dict, duration: int) -> str:
        """ë‰´ìŠ¤ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± (duration ìµœì í™”)"""
        title = news_data['title']
        category = NEWS_CATEGORIES.get(news_data['category'], {}).get('name', 'ë‰´ìŠ¤')
        
        # durationì— ë”°ë¥¸ ìŠ¤í¬ë¦½íŠ¸ ê¸¸ì´ ì¡°ì • (ëŒ€ëµ 150ì/ë¶„)
        target_chars = int(duration * 2.5)  # 15ì´ˆ = ì•½ 37ì
        
        if duration <= 15:
            # ì§§ì€ ë²„ì „ (15ì´ˆ)
            script = f"{category} ì†ë³´ì…ë‹ˆë‹¤. {title}. ì´ ì†Œì‹ì— ëŒ€í•œ ì—¬ëŸ¬ë¶„ì˜ ìƒê°ì€ ì–´ë– ì‹ ê°€ìš”?"
        elif duration <= 30:
            # ì¤‘ê°„ ë²„ì „ (30ì´ˆ)
            summary = news_data.get('summary', title)[:100]
            script = f"{category} ê¸´ê¸‰ ë‰´ìŠ¤ë¥¼ ì „í•´ë“œë¦½ë‹ˆë‹¤. {title}. {summary}. ê³„ì†í•´ì„œ ê´€ë ¨ ì†Œì‹ì„ ì „í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
        else:
            # ê¸´ ë²„ì „ (60ì´ˆ)
            summary = news_data.get('summary', title)
            script = f"ì•ˆë…•í•˜ì„¸ìš”. {category} ì†ë³´ë¥¼ ì „í•´ë“œë¦½ë‹ˆë‹¤. {title}. {summary}. ì´ ì‚¬ê±´ì˜ ìì„¸í•œ ë‚´ìš©ê³¼ ì•ìœ¼ë¡œì˜ ì „ë§ì— ëŒ€í•´ ê³„ì† ì£¼ëª©í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤."
        
        # ëª©í‘œ ê¸¸ì´ì— ë§ê²Œ ì¡°ì •
        if len(script) > target_chars:
            script = script[:target_chars-3] + "..."
        
        return script
    
    async def _create_visual_content(self, news_data: Dict, style: str, duration: int) -> Dict:
        """ë¹„ì£¼ì–¼ ì½˜í…ì¸  ìƒì„±"""
        try:
            # ìŠ¤íƒ€ì¼ë³„ ë¹„ì£¼ì–¼ ìƒì„±
            if style == "trending":
                visual_path = await self._create_trending_visual(news_data, duration)
            elif style == "news":
                visual_path = await self._create_news_visual(news_data, duration)
            else:  # minimal
                visual_path = await self._create_minimal_visual(news_data, duration)
            
            return {
                "success": True,
                "visual_path": visual_path,
                "style": style
            }
            
        except Exception as e:
            logger.error(f"ë¹„ì£¼ì–¼ ìƒì„± ì˜¤ë¥˜: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    async def _create_trending_visual(self, news_data: Dict, duration: int) -> str:
        """íŠ¸ë Œë”© ìŠ¤íƒ€ì¼ ë¹„ì£¼ì–¼ ìƒì„± (ì¸ìŠ¤íƒ€ê·¸ë¨ ì•Œê³ ë¦¬ì¦˜ ìµœì í™”)"""
        try:
            # 9:16 ë¹„ìœ¨ (1080x1920)
            width, height = 1080, 1920
            fps = 30
            
            # ë°°ê²½ ê·¸ë¼ë°ì´ì…˜ ìƒì„±
            background_frames = []
            for frame_num in range(int(duration * fps)):
                # ë™ì  ê·¸ë¼ë°ì´ì…˜ ë°°ê²½
                img = Image.new('RGB', (width, height))
                draw = ImageDraw.Draw(img)
                
                # ì‹œê°„ì— ë”°ë¥¸ ìƒ‰ìƒ ë³€í™”
                hue = (frame_num * 2) % 360
                color1 = self._hsv_to_rgb(hue, 0.8, 0.9)
                color2 = self._hsv_to_rgb((hue + 60) % 360, 0.6, 0.7)
                
                # ê·¸ë¼ë°ì´ì…˜ ê·¸ë¦¬ê¸°
                for y in range(height):
                    ratio = y / height
                    r = int(color1[0] * (1-ratio) + color2[0] * ratio)
                    g = int(color1[1] * (1-ratio) + color2[1] * ratio)
                    b = int(color1[2] * (1-ratio) + color2[2] * ratio)
                    draw.line([(0, y), (width, y)], fill=(r, g, b))
                
                # ì œëª© í…ìŠ¤íŠ¸ ì¶”ê°€ (ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©)
                # ì œëª©ì„ ì—¬ëŸ¬ ì¤„ë¡œ ë¶„í• 
                title_lines = self._wrap_text(news_data['title'], 12)
                
                # í…ìŠ¤íŠ¸ ê·¸ë¦¼ì íš¨ê³¼
                shadow_offset = 5
                for i, line in enumerate(title_lines[:3]):  # ìµœëŒ€ 3ì¤„
                    y_pos = height//2 - 100 + i * 100
                    
                    # ê·¸ë¦¼ì
                    draw.text((width//2 - len(line)*20 + shadow_offset, y_pos + shadow_offset), 
                             line, fill=(0, 0, 0), anchor="mm")
                    
                    # ë©”ì¸ í…ìŠ¤íŠ¸
                    draw.text((width//2, y_pos), line, fill=(255, 255, 255), anchor="mm")
                
                # numpy ë°°ì—´ë¡œ ë³€í™˜
                frame_array = np.array(img)
                background_frames.append(frame_array)
            
            # ë¹„ë””ì˜¤ íŒŒì¼ë¡œ ì €ì¥
            visual_filename = f"visual_trending_{news_data['id']}_{int(time.time())}.mp4"
            visual_path = os.path.join(self.temp_dir, visual_filename)
            
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(visual_path, fourcc, fps, (width, height))
            
            for frame in background_frames:
                # BGRë¡œ ë³€í™˜ (OpenCV ìš”êµ¬ì‚¬í•­)
                frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
                out.write(frame_bgr)
            
            out.release()
            
            logger.info(f"âœ… íŠ¸ë Œë”© ë¹„ì£¼ì–¼ ìƒì„± ì™„ë£Œ: {visual_path}")
            return visual_path
            
        except Exception as e:
            logger.error(f"íŠ¸ë Œë”© ë¹„ì£¼ì–¼ ìƒì„± ì˜¤ë¥˜: {e}")
            raise
    
    async def _create_news_visual(self, news_data: Dict, duration: int) -> str:
        """ë‰´ìŠ¤ ìŠ¤íƒ€ì¼ ë¹„ì£¼ì–¼ ìƒì„±"""
        # ê°„ë‹¨í•œ ë‰´ìŠ¤ ìŠ¤íƒ€ì¼ êµ¬í˜„
        return await self._create_trending_visual(news_data, duration)
    
    async def _create_minimal_visual(self, news_data: Dict, duration: int) -> str:
        """ë¯¸ë‹ˆë©€ ìŠ¤íƒ€ì¼ ë¹„ì£¼ì–¼ ìƒì„±"""
        # ê°„ë‹¨í•œ ë¯¸ë‹ˆë©€ ìŠ¤íƒ€ì¼ êµ¬í˜„
        return await self._create_trending_visual(news_data, duration)
    
    def _hsv_to_rgb(self, h: float, s: float, v: float) -> tuple:
        """HSV to RGB ë³€í™˜"""
        import colorsys
        r, g, b = colorsys.hsv_to_rgb(h/360, s, v)
        return (int(r*255), int(g*255), int(b*255))
    
    def _wrap_text(self, text: str, max_chars: int) -> List[str]:
        """í…ìŠ¤íŠ¸ë¥¼ ì—¬ëŸ¬ ì¤„ë¡œ ë¶„í• """
        words = text.split()
        lines = []
        current_line = ""
        
        for word in words:
            if len(current_line + " " + word) <= max_chars:
                current_line += " " + word if current_line else word
            else:
                if current_line:
                    lines.append(current_line)
                current_line = word
        
        if current_line:
            lines.append(current_line)
        
        return lines
    
    async def _generate_captions(self, news_data: Dict) -> Dict:
        """ìë§‰ ìƒì„±"""
        try:
            # ê°„ë‹¨í•œ ìë§‰ ë°ì´í„° ìƒì„±
            captions = [
                {"start": 0, "end": 3, "text": "ì†ë³´"},
                {"start": 3, "end": 10, "text": news_data['title'][:30]},
                {"start": 10, "end": 15, "text": "ë” ë§ì€ ë‰´ìŠ¤ëŠ” íŒ”ë¡œìš°!"}
            ]
            
            return {
                "success": True,
                "captions": captions
            }
            
        except Exception as e:
            logger.error(f"ìë§‰ ìƒì„± ì˜¤ë¥˜: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    async def _compose_final_video(self, audio_path: str, visual_path: str, captions: List[Dict], 
                                 news_data: Dict, style: str, duration: int) -> Dict:
        """ìµœì¢… ë¹„ë””ì˜¤ í•©ì„± (moviepy ì„¤ì¹˜ ì²´í¬)"""
        try:
            # MoviePyê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ ë¹„ë””ì˜¤ë§Œ ë°˜í™˜
            try:
                from moviepy.editor import VideoFileClip, AudioFileClip, TextClip, CompositeVideoClip
            except ImportError:
                logger.warning("MoviePyê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ. ê¸°ë³¸ ë¹„ë””ì˜¤ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.")
                
                # íŒŒì¼ í¬ê¸° í™•ì¸
                file_size = os.path.getsize(visual_path) / (1024 * 1024)  # MB
                
                return {
                    "success": True,
                    "video_path": visual_path,
                    "file_size_mb": round(file_size, 1),
                    "duration": duration,
                    "message": f"ê¸°ë³¸ ë¹„ë””ì˜¤ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤! ({file_size:.1f}MB)"
                }
            
            # MoviePyë¥¼ ì‚¬ìš©í•œ ë¹„ë””ì˜¤ í•©ì„±
            video_clip = VideoFileClip(visual_path)
            audio_clip = AudioFileClip(audio_path)
            
            # ì˜¤ë””ì˜¤ ê¸¸ì´ì— ë§ê²Œ ë¹„ë””ì˜¤ ì¡°ì •
            if video_clip.duration > audio_clip.duration:
                video_clip = video_clip.subclip(0, audio_clip.duration)
            elif video_clip.duration < audio_clip.duration:
                audio_clip = audio_clip.subclip(0, video_clip.duration)
            
            # ì˜¤ë””ì˜¤ ì¶”ê°€
            final_video = video_clip.set_audio(audio_clip)
            
            # ìµœì¢… ë¹„ë””ì˜¤ ì €ì¥
            output_filename = f"reel_{news_data['id']}_{int(time.time())}.mp4"
            output_path = os.path.join(self.output_dir, output_filename)
            
            final_video.write_videofile(
                output_path,
                fps=30,
                audio_codec='aac',
                codec='libx264',
                verbose=False,
                logger=None
            )
            
            # í´ë¦½ ë©”ëª¨ë¦¬ í•´ì œ
            video_clip.close()
            audio_clip.close()
            final_video.close()
            
            # íŒŒì¼ í¬ê¸° í™•ì¸
            file_size = os.path.getsize(output_path) / (1024 * 1024)  # MB
            
            logger.info(f"ğŸ¬ ë¦´ìŠ¤ ì œì‘ ì™„ë£Œ: {output_path} ({file_size:.1f}MB)")
            
            return {
                "success": True,
                "video_path": output_path,
                "file_size_mb": round(file_size, 1),
                "duration": duration,
                "message": f"ë¦´ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì œì‘ë˜ì—ˆìŠµë‹ˆë‹¤! ({file_size:.1f}MB)"
            }
            
        except Exception as e:
            logger.error(f"ìµœì¢… ë¹„ë””ì˜¤ í•©ì„± ì˜¤ë¥˜: {e}")
            
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ ë¹„ë””ì˜¤ ë°˜í™˜
            if os.path.exists(visual_path):
                file_size = os.path.getsize(visual_path) / (1024 * 1024)
                return {
                    "success": True,
                    "video_path": visual_path,
                    "file_size_mb": round(file_size, 1),
                    "duration": duration,
                    "message": f"ê¸°ë³¸ ë¹„ë””ì˜¤ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤! ({file_size:.1f}MB)"
                }
            else:
                return {
                    "success": False,
                    "error": str(e),
                    "message": "ë¹„ë””ì˜¤ í•©ì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
                }

# AI ì½˜í…ì¸  ìƒì„± ì‹œìŠ¤í…œ (í–¥ìƒë¨)
class AdvancedContentGenerator:
    def __init__(self):
        api_key = os.getenv('OPENAI_API_KEY')
        
        if not api_key:
            logger.warning("âš ï¸ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. AI ê¸°ëŠ¥ì´ ì œí•œë©ë‹ˆë‹¤.")
            self.openai_client = None
            return
        
        try:
            if OPENAI_V1:
                self.openai_client = openai.OpenAI(api_key=api_key)
            else:
                openai.api_key = api_key
                self.openai_client = openai
            
            print(f"âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ (v{openai.__version__})")
            
        except Exception as e:
            logger.error(f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
            self.openai_client = None
    
    async def generate_viral_caption(self, news_data: Dict, style: str = "viral") -> Dict:
        """ë°”ì´ëŸ´ ìº¡ì…˜ ìƒì„± (ì¸ìŠ¤íƒ€ê·¸ë¨ ì•Œê³ ë¦¬ì¦˜ ìµœì í™”)"""
        
        if not self.openai_client:
            return self._generate_fallback_caption(news_data)
        
        style_prompts = {
            "viral": "ë°”ì´ëŸ´ë˜ê¸° ì‰¬ìš´ ìê·¹ì ì´ê³  í˜¸ê¸°ì‹¬ì„ ìê·¹í•˜ëŠ” ìŠ¤íƒ€ì¼ë¡œ",
            "engaging": "ì°¸ì—¬ë¥¼ ìœ ë„í•˜ëŠ” ë§¤ë ¥ì ì¸ ìŠ¤íƒ€ì¼ë¡œ", 
            "informative": "ì •ë³´ ì „ë‹¬ì— ì¤‘ì ì„ ë‘” ì „ë¬¸ì ì¸ ìŠ¤íƒ€ì¼ë¡œ",
            "trendy": "íŠ¸ë Œë“œë¥¼ ë°˜ì˜í•œ MZì„¸ëŒ€ ì¹œí™”ì ì¸ ìŠ¤íƒ€ì¼ë¡œ"
        }
        
        prompt = f"""
ë‹¤ìŒ ë‰´ìŠ¤ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¸ìŠ¤íƒ€ê·¸ë¨ ë¦´ìŠ¤/í¬ìŠ¤íŠ¸ìš© ìº¡ì…˜ì„ {style_prompts.get(style, 'ìì—°ìŠ¤ëŸ¬ìš´ ìŠ¤íƒ€ì¼ë¡œ')} ì‘ì„±í•´ì£¼ì„¸ìš”.

ë‰´ìŠ¤ ì œëª©: {news_data['title']}
ë‰´ìŠ¤ ìš”ì•½: {news_data['summary']}
ì¹´í…Œê³ ë¦¬: {news_data['category']}

ì¸ìŠ¤íƒ€ê·¸ë¨ ì•Œê³ ë¦¬ì¦˜ ìµœì í™” ìš”êµ¬ì‚¬í•­:
1. ì²« 3ì´ˆ ì•ˆì— ì‹œì„ ì„ ì‚¬ë¡œì¡ëŠ” í›… ë¬¸ì¥
2. í˜¸ê¸°ì‹¬ì„ ìê·¹í•˜ëŠ” ì§ˆë¬¸ í¬í•¨
3. ì´ëª¨ì§€ 3-5ê°œ ì „ëµì  ì‚¬ìš©
4. ëŒ“ê¸€ì„ ìœ ë„í•˜ëŠ” CTA(Call to Action)
5. 2-4ì¤„ì˜ ê°„ê²°í•œ êµ¬ì„±
6. íŠ¸ë Œë”© ìš©ì–´ í™œìš©

ì˜ˆì‹œ êµ¬ì¡°:
ğŸš¨ [ì¶©ê²©ì ì¸ í›…] 
[í•µì‹¬ ì •ë³´ + ê°ì • ìê·¹]
[ì§ˆë¬¸ìœ¼ë¡œ ì°¸ì—¬ ìœ ë„]
[CTA + ì´ëª¨ì§€]

ìº¡ì…˜ë§Œ ë‹µë³€í•˜ì„¸ìš”:
"""
        
        try:
            if OPENAI_V1:
                response = self.openai_client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {
                            "role": "system",
                            "content": "ë‹¹ì‹ ì€ ì¸ìŠ¤íƒ€ê·¸ë¨ ì•Œê³ ë¦¬ì¦˜ì„ ì˜ ì´í•´í•˜ëŠ” ì „ë¬¸ SNS ë§ˆì¼€í„°ì…ë‹ˆë‹¤. ë°”ì´ëŸ´ ì½˜í…ì¸  ì œì‘ì˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."
                        },
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=400,
                    temperature=0.9
                )
                caption = response.choices[0].message.content.strip()
            else:
                response = openai.ChatCompletion.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {
                            "role": "system",
                            "content": "ë‹¹ì‹ ì€ ì¸ìŠ¤íƒ€ê·¸ë¨ ì•Œê³ ë¦¬ì¦˜ì„ ì˜ ì´í•´í•˜ëŠ” ì „ë¬¸ SNS ë§ˆì¼€í„°ì…ë‹ˆë‹¤. ë°”ì´ëŸ´ ì½˜í…ì¸  ì œì‘ì˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."
                        },
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=400,
                    temperature=0.9
                )
                caption = response.choices[0].message.content.strip()
            
            return {
                'caption': caption,
                'keypoint': 'ë°”ì´ëŸ´ ë‰´ìŠ¤',
                'target_emotion': 'í˜¸ê¸°ì‹¬/ì¶©ê²©',
                'style': style,
                'estimated_engagement': 'high'
            }
            
        except Exception as e:
            logger.error(f"ë°”ì´ëŸ´ ìº¡ì…˜ ìƒì„± ì˜¤ë¥˜: {e}")
            return self._generate_fallback_caption(news_data)
    
    async def generate_trending_hashtags(self, news_data: Dict) -> List[str]:
        """íŠ¸ë Œë”© í•´ì‹œíƒœê·¸ ìƒì„±"""
        
        if not self.openai_client:
            return self._get_category_hashtags(news_data['category'])
        
        prompt = f"""
ë‹¤ìŒ ë‰´ìŠ¤ì— ì í•©í•œ ì¸ìŠ¤íƒ€ê·¸ë¨ í•´ì‹œíƒœê·¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

ë‰´ìŠ¤ ì œëª©: {news_data['title']}
ì¹´í…Œê³ ë¦¬: {news_data['category']}

í•´ì‹œíƒœê·¸ ìš”êµ¬ì‚¬í•­:
1. ì´ 15-20ê°œ (ìµœì  ë…¸ì¶œì„ ìœ„í•œ ê°œìˆ˜)
2. ì¸ê¸°/íŠ¸ë Œë”© í•´ì‹œíƒœê·¸ í¬í•¨
3. ë‹ˆì¹˜ í•´ì‹œíƒœê·¸ì™€ ë¸Œë¡œë“œ í•´ì‹œíƒœê·¸ ê· í˜•
4. ì¹´í…Œê³ ë¦¬ë³„ íŠ¹í™” í•´ì‹œíƒœê·¸
5. í•œêµ­ì–´/ì˜ì–´ í˜¼í•©

í•´ì‹œíƒœê·¸ë§Œ ë‚˜ì—´í•´ì„œ ë‹µë³€ (# í¬í•¨, ê³µë°±ìœ¼ë¡œ êµ¬ë¶„):
"""
        
        try:
            if OPENAI_V1:
                response = self.openai_client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[{"role": "user", "content": prompt}],
                    max_tokens=300,
                    temperature=0.8
                )
                hashtags_text = response.choices[0].message.content.strip()
            else:
                response = openai.ChatCompletion.create(
                    model="gpt-3.5-turbo",
                    messages=[{"role": "user", "content": prompt}],
                    max_tokens=300,
                    temperature=0.8
                )
                hashtags_text = response.choices[0].message.content.strip()
            
            hashtags = [tag.strip() for tag in hashtags_text.split() if tag.startswith('#')]
            
            # ì¹´í…Œê³ ë¦¬ë³„ í•„ìˆ˜ í•´ì‹œíƒœê·¸ ì¶”ê°€
            base_hashtags = self._get_trending_hashtags(news_data['category'])
            hashtags.extend(base_hashtags)
            
            # ì¤‘ë³µ ì œê±° ë° ìµœì í™”
            unique_hashtags = list(dict.fromkeys(hashtags))
            return unique_hashtags[:20]
            
        except Exception as e:
            logger.error(f"í•´ì‹œíƒœê·¸ ìƒì„± ì˜¤ë¥˜: {e}")
            return self._get_category_hashtags(news_data['category'])
    
    def _get_trending_hashtags(self, category: str) -> List[str]:
        """ì¹´í…Œê³ ë¦¬ë³„ íŠ¸ë Œë”© í•´ì‹œíƒœê·¸"""
        trending_hashtags = {
            "stock": [
                "#ì£¼ì‹", "#íˆ¬ì", "#ì¬í…Œí¬", "#ê²½ì œ", "#ì½”ìŠ¤í”¼", "#ì¦ì‹œ", 
                "#stockmarket", "#investment", "#money", "#finance",
                "#ë¶€ìë˜ê¸°", "#ì£¼ë¦°ì´", "#ê²½ì œë‰´ìŠ¤", "#ê¸‰ë“±", "#ê¸‰ë½"
            ],
            "politics": [
                "#ì •ì¹˜", "#ë‰´ìŠ¤", "#ëŒ€í†µë ¹", "#êµ­íšŒ", "#ì •ë¶€", "#ì‹œì‚¬",
                "#politics", "#news", "#breaking", "#korea",
                "#ì •ì¹˜ë‰´ìŠ¤", "#ì†ë³´", "#ê¸´ê¸‰", "#ë…¼ë€", "#ë°œì–¸"
            ],
            "international": [
                "#í•´ì™¸ë‰´ìŠ¤", "#êµ­ì œë‰´ìŠ¤", "#ì„¸ê³„ë‰´ìŠ¤", "#ê¸€ë¡œë²Œ", "#ì™¸ì‹ ",
                "#worldnews", "#international", "#global", "#breaking",
                "#ë¯¸êµ­", "#ì¤‘êµ­", "#ì¼ë³¸", "#ìœ ëŸ½", "#ì „ìŸ"
            ],
            "domestic": [
                "#êµ­ë‚´ë‰´ìŠ¤", "#ì‚¬íšŒì´ìŠˆ", "#ì‹œì‚¬", "#í•œêµ­ë‰´ìŠ¤", "#ì†ë³´",
                "#koreanews", "#society", "#issue", "#breaking",
                "#ì‚¬ê±´", "#ì‚¬ê³ ", "#ë…¼ë€", "#ì´ìŠˆ", "#í™”ì œ"
            ],
            "technology": [
                "#ê¸°ìˆ ë‰´ìŠ¤", "#ITë‰´ìŠ¤", "#ì¸ê³µì§€ëŠ¥", "#í…Œí¬", "#í˜ì‹ ", "#AI",
                "#technology", "#tech", "#innovation", "#startup",
                "#ì‚¼ì„±", "#ì• í”Œ", "#êµ¬ê¸€", "#ì‹ ì œí’ˆ", "#ì¶œì‹œ"
            ],
            "entertainment": [
                "#ì—°ì˜ˆë‰´ìŠ¤", "#ì—°ì˜ˆì¸", "#ì•„ì´ëŒ", "#ì¼€ì´íŒ", "#ë“œë¼ë§ˆ",
                "#entertainment", "#kpop", "#celebrity", "#drama",
                "#BTS", "#ë¸”ë™í•‘í¬", "#ì•„ì´ìœ ", "#ë°ë·”", "#ì»´ë°±"
            ]
        }
        
        # ê³µí†µ íŠ¸ë Œë”© í•´ì‹œíƒœê·¸ ì¶”ê°€
        common_trending = [
            "#íŠ¸ë Œë“œ", "#í™”ì œ", "#ì´ìŠˆ", "#íŒ”ë¡œìš°", "#ì¢‹ì•„ìš”",
            "#trending", "#viral", "#fyp", "#reels", "#instagood"
        ]
        
        category_tags = trending_hashtags.get(category, ["#ë‰´ìŠ¤", "#ì´ìŠˆ"])
        return category_tags + common_trending
    
    def _get_category_hashtags(self, category: str) -> List[str]:
        """ê¸°ë³¸ ì¹´í…Œê³ ë¦¬ë³„ í•´ì‹œíƒœê·¸"""
        return self._get_trending_hashtags(category)[:15]
    
    def _generate_fallback_caption(self, news_data: Dict) -> Dict:
        """í´ë°± ìº¡ì…˜ ìƒì„± (AI ì—†ì´)"""
        title = news_data['title']
        category_name = NEWS_CATEGORIES.get(news_data['category'], {}).get('name', 'ë‰´ìŠ¤')
        
        viral_hooks = [
            "ğŸš¨ ì´ê±° ì§„ì§œì•¼?",
            "ğŸ˜± ì¶©ê²©ì ì¸ ì†Œì‹!",
            "ğŸ”¥ ì§€ê¸ˆ í™”ì œ!",
            "âš¡ ì†ë³´ í„°ì¡Œë‹¤!",
            "ğŸ’¥ ëŒ€ë°• ì‚¬ê±´!"
        ]
        
        hook = random.choice(viral_hooks)
        
        return {
            'caption': f"{hook}\n\n{title}\n\nì—¬ëŸ¬ë¶„ ìƒê°ì€? ëŒ“ê¸€ë¡œ ì•Œë ¤ì£¼ì„¸ìš”! ğŸ‘‡\n\n#ì†ë³´ #ë‰´ìŠ¤ #ì´ìŠˆ",
            'keypoint': 'ë‰´ìŠ¤ ì†ë³´',
            'target_emotion': 'í˜¸ê¸°ì‹¬',
            'style': 'viral'
        }

# Instagram ì„œë¹„ìŠ¤ í´ë˜ìŠ¤ í™•ì¥ (ë¦´ìŠ¤ ì§€ì›)
class AdvancedInstagramService:
    def __init__(self):
        self.access_token = os.getenv('INSTAGRAM_ACCESS_TOKEN')
        self.business_account_id = os.getenv('INSTAGRAM_BUSINESS_ACCOUNT_ID')
        self.base_url = "https://graph.facebook.com"
        self.api_version = "v18.0"
        
    def validate_credentials(self) -> bool:
        """ì¸ì¦ ì •ë³´ ìœ íš¨ì„± ê²€ì‚¬"""
        if not self.access_token or not self.business_account_id:
            logger.error("Instagram ì¸ì¦ ì •ë³´ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return False
        return True
    
    async def test_connection(self) -> Dict:
        """Instagram ì—°ê²° í…ŒìŠ¤íŠ¸"""
        if not self.validate_credentials():
            return {
                "success": False,
                "error": "Instagram ì¸ì¦ ì •ë³´ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤",
                "details": {
                    "access_token": bool(self.access_token),
                    "business_id": bool(self.business_account_id)
                }
            }
        
        try:
            url = f"{self.base_url}/{self.api_version}/{self.business_account_id}"
            params = {
                'fields': 'id,name,username,followers_count',
                'access_token': self.access_token
            }
            
            response = requests.get(url, params=params, timeout=15)
            
            logger.info(f"Instagram API í…ŒìŠ¤íŠ¸ - ìƒíƒœì½”ë“œ: {response.status_code}")
            logger.info(f"Instagram API ì‘ë‹µ: {response.text[:200]}...")
            
            if response.status_code == 200:
                data = response.json()
                return {
                    "success": True,
                    "account_info": data,
                    "message": f"âœ… Instagram ì—°ê²° ì„±ê³µ: @{data.get('username', 'N/A')}"
                }
            else:
                error_data = response.json()
                return {
                    "success": False,
                    "error": f"Instagram API ì˜¤ë¥˜ (ì½”ë“œ: {response.status_code})",
                    "details": error_data
                }
                
        except Exception as e:
            logger.error(f"Instagram ì—°ê²° í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
            return {
                "success": False,
                "error": f"ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}"
            }
    
    async def post_reel_with_video(self, caption: str, video_url: str) -> Dict:
        """ë¦´ìŠ¤ ì—…ë¡œë“œ (ë¹„ë””ì˜¤ íŒŒì¼)"""
        try:
            if not self.validate_credentials():
                return {
                    "success": False,
                    "error": "Instagram ì¸ì¦ ì •ë³´ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤",
                    "message": "Instagram ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”"
                }
            
            logger.info(f"ğŸ¬ Instagram ë¦´ìŠ¤ ì—…ë¡œë“œ ì‹œì‘")
            logger.info(f"  ë¹„ë””ì˜¤: {video_url}")
            logger.info(f"  ìº¡ì…˜: {caption[:100]}...")
            
            # 1ë‹¨ê³„: ë¦´ìŠ¤ ì»¨í…Œì´ë„ˆ ìƒì„±
            container_result = await self._create_reel_container(video_url, caption)
            
            if not container_result or not container_result.get("success"):
                return {
                    "success": False,
                    "step": "container_creation",
                    "error": container_result.get("error") if container_result else "ì»¨í…Œì´ë„ˆ ìƒì„± ì‹¤íŒ¨",
                    "message": "ë¦´ìŠ¤ ì»¨í…Œì´ë„ˆ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
                }
            
            container_id = container_result["container_id"]
            logger.info(f"âœ… ë¦´ìŠ¤ ì»¨í…Œì´ë„ˆ ìƒì„± ì™„ë£Œ: {container_id}")
            
            # 2ë‹¨ê³„: ì²˜ë¦¬ ëŒ€ê¸° (ë¦´ìŠ¤ëŠ” ì²˜ë¦¬ ì‹œê°„ì´ ë” í•„ìš”)
            logger.info("â³ ë¦´ìŠ¤ ì²˜ë¦¬ ëŒ€ê¸° (10ì´ˆ)...")
            await asyncio.sleep(10)
            
            # 3ë‹¨ê³„: ë¦´ìŠ¤ ë°œí–‰
            publish_result = await self.publish_media(container_id)
            
            if publish_result.get("success"):
                logger.info(f"ğŸ‰ Instagram ë¦´ìŠ¤ ì—…ë¡œë“œ ì™„ë£Œ!")
                return {
                    "success": True,
                    "container_id": container_id,
                    "post_id": publish_result.get("post_id"),
                    "instagram_url": publish_result.get("instagram_url"),
                    "message": "Instagram ë¦´ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!",
                    "post_type": "reel"
                }
            else:
                return {
                    "success": False,
                    "step": "media_publish",
                    "container_id": container_id,
                    "error": publish_result.get("error"),
                    "message": f"ë¦´ìŠ¤ ë°œí–‰ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {publish_result.get('message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}"
                }
                
        except Exception as e:
            logger.error(f"âŒ Instagram ë¦´ìŠ¤ ì—…ë¡œë“œ ì˜¤ë¥˜: {e}")
            return {
                "success": False,
                "step": "general",
                "error": str(e),
                "message": f"Instagram ë¦´ìŠ¤ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            }
    
    async def _create_reel_container(self, video_url: str, caption: str) -> Optional[Dict]:
        """ë¦´ìŠ¤ ì»¨í…Œì´ë„ˆ ìƒì„±"""
        if not self.validate_credentials():
            return None
            
        url = f"{self.base_url}/{self.api_version}/{self.business_account_id}/media"
        
        logger.info(f"ğŸ“± Instagram ë¦´ìŠ¤ ì»¨í…Œì´ë„ˆ ìƒì„±:")
        logger.info(f"  - URL: {url}")
        logger.info(f"  - Video URL: {video_url}")
        logger.info(f"  - Caption ê¸¸ì´: {len(caption)}ì")
        
        params = {
            'video_url': video_url,
            'media_type': 'REELS',  # ë¦´ìŠ¤ íƒ€ì… ì§€ì •
            'caption': caption[:2200],  # Instagram ìº¡ì…˜ ê¸¸ì´ ì œí•œ
            'access_token': self.access_token
        }
        
        try:
            response = requests.post(url, data=params, timeout=30)
            
            logger.info(f"ë¦´ìŠ¤ ì»¨í…Œì´ë„ˆ ì‘ë‹µ ì½”ë“œ: {response.status_code}")
            logger.info(f"ë¦´ìŠ¤ ì»¨í…Œì´ë„ˆ ì‘ë‹µ: {response.text}")
            
            if response.status_code == 200:
                data = response.json()
                container_id = data.get('id')
                logger.info(f"âœ… ë¦´ìŠ¤ ì»¨í…Œì´ë„ˆ ìƒì„± ì„±ê³µ: {container_id}")
                
                return {
                    "success": True,
                    "container_id": container_id,
                    "response": data
                }
            else:
                error_data = response.json()
                logger.error(f"âŒ ë¦´ìŠ¤ ì»¨í…Œì´ë„ˆ ìƒì„± ì‹¤íŒ¨: {error_data}")
                
                return {
                    "success": False,
                    "error": error_data,
                    "status_code": response.status_code
                }
                
        except Exception as e:
            logger.error(f"âŒ ë¦´ìŠ¤ ì»¨í…Œì´ë„ˆ ìƒì„± ì˜¤ë¥˜: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    async def publish_media(self, creation_id: str) -> Dict:
        """ë¯¸ë””ì–´ ë°œí–‰ (ì´ë¯¸ì§€/ë¦´ìŠ¤ ê³µí†µ)"""
        if not self.validate_credentials():
            return {"success": False, "error": "ì¸ì¦ ì •ë³´ ì—†ìŒ"}
            
        url = f"{self.base_url}/{self.api_version}/{self.business_account_id}/media_publish"
        
        params = {
            'creation_id': creation_id,
            'access_token': self.access_token
        }
        
        try:
            logger.info(f"ğŸ“¤ Instagram ë¯¸ë””ì–´ ë°œí–‰ ì‹œì‘: {creation_id}")
            
            response = requests.post(url, data=params, timeout=30)
            
            logger.info(f"ë¯¸ë””ì–´ ë°œí–‰ ì‘ë‹µ ì½”ë“œ: {response.status_code}")
            logger.info(f"ë¯¸ë””ì–´ ë°œí–‰ ì‘ë‹µ: {response.text}")
            
            if response.status_code == 200:
                data = response.json()
                post_id = data.get('id')
                logger.info(f"ğŸ‰ Instagram ë°œí–‰ ì„±ê³µ! Post ID: {post_id}")
                
                return {
                    "success": True,
                    "post_id": post_id,
                    "message": f"Instagram ë°œí–‰ ì„±ê³µ! ID: {post_id}",
                    "instagram_url": f"https://www.instagram.com/p/{post_id}/" if post_id else None
                }
            else:
                error_data = response.json()
                logger.error(f"âŒ ë¯¸ë””ì–´ ë°œí–‰ ì‹¤íŒ¨: {error_data}")
                
                return {
                    "success": False,
                    "error": error_data,
                    "status_code": response.status_code,
                    "message": f"Instagram ë°œí–‰ ì‹¤íŒ¨: {error_data.get('error', {}).get('message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}"
                }
                
        except Exception as e:
            logger.error(f"âŒ ë¯¸ë””ì–´ ë°œí–‰ ì˜¤ë¥˜: {e}")
            return {
                "success": False,
                "error": str(e),
                "message": f"Instagram ë°œí–‰ ì˜¤ë¥˜: {str(e)}"
            }

# ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” (ë¦´ìŠ¤ í…Œì´ë¸” ì¶”ê°€)
def init_enhanced_db():
    """í–¥ìƒëœ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
    try:
        conn = sqlite3.connect("news_automation.db")
        cursor = conn.cursor()
        
        # ê¸°ì¡´ ë‰´ìŠ¤ í…Œì´ë¸” (title_hash ì»¬ëŸ¼ ì¶”ê°€)
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS news_articles (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                title TEXT NOT NULL,
                title_hash TEXT,
                link TEXT,
                summary TEXT,
                content TEXT,
                source TEXT,
                category TEXT,
                keywords TEXT,
                viral_score REAL,
                scraped_at TEXT,
                published_at TEXT,
                is_processed BOOLEAN DEFAULT FALSE,
                view_count INTEGER DEFAULT 0
            )
        """)
        
        # title_hash ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì¶”ê°€
        try:
            cursor.execute("ALTER TABLE news_articles ADD COLUMN title_hash TEXT")
        except sqlite3.OperationalError:
            pass
        
        try:
            cursor.execute("ALTER TABLE news_articles ADD COLUMN viral_score REAL")
        except sqlite3.OperationalError:
            pass
        
        # ë¦´ìŠ¤ ì œì‘ í…Œì´ë¸” (ìƒˆë¡œ ì¶”ê°€)
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS news_reels (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                news_id INTEGER,
                video_path TEXT,
                audio_path TEXT,
                script TEXT,
                style TEXT,
                duration INTEGER,
                file_size_mb REAL,
                created_at TEXT,
                status TEXT DEFAULT 'created',
                view_count INTEGER DEFAULT 0,
                like_count INTEGER DEFAULT 0,
                FOREIGN KEY (news_id) REFERENCES news_articles (id)
            )
        """)
        
        # ìƒì„±ëœ ì½˜í…ì¸  í…Œì´ë¸” (í™•ì¥)
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS generated_news_content (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                news_id INTEGER,
                caption TEXT,
                hashtags TEXT,
                script_data TEXT,
                style TEXT,
                estimated_engagement TEXT,
                created_at TEXT,
                FOREIGN KEY (news_id) REFERENCES news_articles (id)
            )
        """)
        
        # í¬ìŠ¤íŒ… ê¸°ë¡ í…Œì´ë¸” (ë¦´ìŠ¤ ì§€ì› ì¶”ê°€)
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS news_posts (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                news_id INTEGER,
                content_id INTEGER,
                reel_id INTEGER,
                platform TEXT,
                post_type TEXT DEFAULT 'image',
                post_id TEXT,
                caption TEXT,
                hashtags TEXT,
                media_urls TEXT,
                posted_at TEXT,
                status TEXT DEFAULT 'pending',
                engagement_stats TEXT,
                error_message TEXT,
                instagram_url TEXT,
                reach_count INTEGER DEFAULT 0,
                impression_count INTEGER DEFAULT 0,
                FOREIGN KEY (news_id) REFERENCES news_articles (id),
                FOREIGN KEY (content_id) REFERENCES generated_news_content (id),
                FOREIGN KEY (reel_id) REFERENCES news_reels (id)
            )
        """)
        
        # ì¸ë±ìŠ¤ ìƒì„±
        indexes = [
            "CREATE INDEX IF NOT EXISTS idx_title_hash ON news_articles(title_hash)",
            "CREATE INDEX IF NOT EXISTS idx_category_scraped ON news_articles(category, scraped_at)",
            "CREATE INDEX IF NOT EXISTS idx_viral_score ON news_articles(viral_score DESC)",
            "CREATE INDEX IF NOT EXISTS idx_posts_status ON news_posts(status, posted_at)",
            "CREATE INDEX IF NOT EXISTS idx_reels_status ON news_reels(status, created_at)"
        ]
        
        for index_sql in indexes:
            cursor.execute(index_sql)
        
        conn.commit()
        conn.close()
        logger.info("âœ… í–¥ìƒëœ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
        return True
    except Exception as e:
        logger.error(f"âŒ DB ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
        return False

# FastAPI ì•± ì´ˆê¸°í™”
@asynccontextmanager
async def lifespan(app: FastAPI):
    logger.info("ğŸš€ ADVANCED NEWS AUTOMATION - AI ë‰´ìŠ¤ & ë¦´ìŠ¤ ìë™í™” í”Œë«í¼ ì‹œì‘")
    init_enhanced_db()
    yield
    # ì•± ì¢…ë£Œ ì‹œ ì„¸ì…˜ ì •ë¦¬
    if hasattr(app.state, 'news_scraper'):
        await app.state.news_scraper.close()

app = FastAPI(
    title="ADVANCED NEWS AUTOMATION", 
    description="AI ë‰´ìŠ¤ ìˆ˜ì§‘ + ë¦´ìŠ¤ ì œì‘ + ì¸ìŠ¤íƒ€ê·¸ë¨ ìë™ ì—…ë¡œë“œ",
    version="2.0.0",
    lifespan=lifespan, 
    debug=DEBUG
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

app.get("/favicon.ico", include_in_schema=False)
async def favicon():
    # ê¸°ë³¸ ë¹ˆ ì‘ë‹µ ë˜ëŠ” ì‹¤ì œ favicon íŒŒì¼ ë°˜í™˜
    return Response(status_code=204)

# ì •ì  íŒŒì¼ ì„œë¹™
try:
    app.mount("/generated_videos", StaticFiles(directory=VIDEO_OUTPUT_DIR), name="videos")
    app.mount("/generated_audio", StaticFiles(directory=AUDIO_OUTPUT_DIR), name="audio")
except Exception as e:
    logger.warning(f"ì •ì  íŒŒì¼ ë§ˆìš´íŠ¸ ì‹¤íŒ¨: {e}")

# ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
news_scraper = None
content_generator = None
instagram_service = None
reels_producer = None

def get_news_scraper():
    global news_scraper
    if news_scraper is None:
        news_scraper = AdvancedNewsScrapingSystem()
    return news_scraper

def get_content_generator():
    global content_generator
    if content_generator is None:
        content_generator = AdvancedContentGenerator()
    return content_generator

def get_instagram_service():
    global instagram_service
    if instagram_service is None:
        instagram_service = AdvancedInstagramService()
    return instagram_service

def get_reels_producer():
    global reels_producer
    if reels_producer is None:
        reels_producer = ReelsProductionSystem()
    return reels_producer

# API ë¼ìš°íŠ¸ë“¤

@app.get("/")
async def home():
    """í–¥ìƒëœ í™ˆí˜ì´ì§€"""
    return {
        "title": "ğŸ¬ ADVANCED NEWS AUTOMATION",
        "description": "AI ë‰´ìŠ¤ ìˆ˜ì§‘ + ë¦´ìŠ¤ ì œì‘ + ì¸ìŠ¤íƒ€ê·¸ë¨ ìë™í™”",
        "features": [
            "ğŸ” ë‹¤ì¤‘ ì†ŒìŠ¤ ë‰´ìŠ¤ í¬ë¡¤ë§ (Google News)",
            "ğŸ¤– AI ë°”ì´ëŸ´ ìº¡ì…˜ ìƒì„±",
            "ğŸ¬ ìë™ ë¦´ìŠ¤ ì œì‘ (TTS + ë¹„ì£¼ì–¼)",
            "ğŸ“± ì¸ìŠ¤íƒ€ê·¸ë¨ ìë™ ì—…ë¡œë“œ",
            "ğŸ“Š ì°¸ì—¬ë„ ë¶„ì„ ë° ìµœì í™”"
        ],
        "endpoints": {
            "dashboard": "/dashboard",
            "api_docs": "/docs",
            "health": "/health"
        }
    }

@app.get("/dashboard", response_class=HTMLResponse)
async def dashboard():
    """ëŒ€ì‹œë³´ë“œ í˜ì´ì§€"""
    try:
        possible_paths = ["dashboard.html", "./dashboard.html", "/app/dashboard.html"]
        
        for path in possible_paths:
            if os.path.exists(path):
                with open(path, "r", encoding="utf-8") as f:
                    return f.read()
        # íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´ ê¸°ë³¸ ëŒ€ì‹œë³´ë“œ ë°˜í™˜
        return get_default_dashboard_html()
    
    except Exception as e:
        logger.error(f"ëŒ€ì‹œë³´ë“œ ë¡œë“œ ì˜¤ë¥˜: {e}")
        return get_default_dashboard_html()

def get_default_dashboard_html():
    """ê¸°ë³¸ ëŒ€ì‹œë³´ë“œ HTML"""
    return """
    <!DOCTYPE html>
    <html><head><title>News Automation Dashboard</title></head>
    <body>
    <h1>NEWS AUTOMATION - Render ë°°í¬ ì„±ê³µ!</h1>
    <p>API ì„œë²„ê°€ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤.</p>
    <p><a href="/docs">API ë¬¸ì„œ ë³´ê¸°</a></p>
    <p><a href="/health">ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸</a></p>
    </body></html>
    """


@app.post("/api/scrape-news")
async def scrape_news_api(request: NewsRequest):
    """í–¥ìƒëœ ë‰´ìŠ¤ ìˆ˜ì§‘ API"""
    try:
        scraper = get_news_scraper()
        news_list = await scraper.scrape_latest_news(request.category, request.max_articles)
        
        if not news_list:
            return {"success": False, "message": "ìˆ˜ì§‘ëœ ìƒˆë¡œìš´ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤"}
        
        # DBì— ì €ì¥
        saved_news = []
        conn = sqlite3.connect("news_automation.db")
        cursor = conn.cursor()
        
        for news in news_list:
            cursor.execute("""
                INSERT INTO news_articles 
                (title, title_hash, link, summary, source, category, keywords, viral_score, scraped_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                news['title'],
                news['title_hash'],
                news['link'],
                news['summary'],
                news['source'],
                news['category'],
                json.dumps(news['keywords']),
                news['viral_score'],
                news['scraped_at']
            ))
            
            news_id = cursor.lastrowid
            news['id'] = news_id
            saved_news.append(news)
        
        conn.commit()
        conn.close()
        
        return {
            "success": True,
            "message": f"{len(saved_news)}ê°œì˜ ìƒˆë¡œìš´ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤",
            "news": saved_news,
            "highest_viral_score": max([n['viral_score'] for n in saved_news]) if saved_news else 0
        }
        
    except Exception as e:
        logger.error(f"ë‰´ìŠ¤ ìˆ˜ì§‘ API ì˜¤ë¥˜: {e}")
        return {"success": False, "error": str(e)}

@app.get("/health")
async def health_check():
    return {"status": "healthy", "service": "news_automation"}

@app.post("/api/create-reel/{news_id}")
async def create_reel_api(news_id: int, request: ReelsRequest):
    """ë¦´ìŠ¤ ì œì‘ API"""
    try:
        # ë‰´ìŠ¤ ë°ì´í„° ì¡°íšŒ
        conn = sqlite3.connect("news_automation.db")
        cursor = conn.cursor()
        cursor.execute("SELECT * FROM news_articles WHERE id = ?", (news_id,))
        news_row = cursor.fetchone()
        
        if not news_row:
            return {"success": False, "message": "ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}
        
        # ë‰´ìŠ¤ ë°ì´í„° êµ¬ì„±
        news_data = {
            'id': news_row[0],
            'title': news_row[1],
            'link': news_row[3],
            'summary': news_row[4],
            'source': news_row[6],
            'category': news_row[7],
            'keywords': json.loads(news_row[8]) if news_row[8] else []
        }
        
        # ë¦´ìŠ¤ ì œì‘
        producer = get_reels_producer()
        result = await producer.create_news_reel(
            news_data, 
            request.video_style, 
            request.duration
        )
        
        if result["success"]:
            # DBì— ë¦´ìŠ¤ ì •ë³´ ì €ì¥
            cursor.execute("""
                INSERT INTO news_reels 
                (news_id, video_path, style, duration, file_size_mb, created_at, status)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            """, (
                news_id,
                result["video_path"],
                request.video_style,
                request.duration,
                result["file_size_mb"],
                datetime.now().isoformat(),
                'created'
            ))
            
            reel_id = cursor.lastrowid
            conn.commit()
            
            result["reel_id"] = reel_id
            result["video_url"] = f"/generated_videos/{os.path.basename(result['video_path'])}"
        
        conn.close()
        return result
        
    except Exception as e:
        logger.error(f"ë¦´ìŠ¤ ì œì‘ API ì˜¤ë¥˜: {e}")
        return {"success": False, "error": str(e)}

@app.post("/api/post-reel-to-instagram/{reel_id}")
async def post_reel_to_instagram_api(reel_id: int):
    """ë¦´ìŠ¤ Instagram ì—…ë¡œë“œ API"""
    try:
        # ë¦´ìŠ¤ ë°ì´í„° ì¡°íšŒ
        conn = sqlite3.connect("news_automation.db")
        cursor = conn.cursor()
        cursor.execute("""
            SELECT nr.*, na.title, na.category 
            FROM news_reels nr
            JOIN news_articles na ON nr.news_id = na.id
            WHERE nr.id = ?
        """, (reel_id,))
        
        row = cursor.fetchone()
        if not row:
            return {"success": False, "message": "ë¦´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}
        
        # ë¦´ìŠ¤ ë°ì´í„° êµ¬ì„±
        video_path = row[2]
        news_title = row[9]
        category = row[10]
        
        # ë°”ì´ëŸ´ ìº¡ì…˜ ìƒì„±
        generator = get_content_generator()
        news_data = {
            'id': row[1],
            'title': news_title,
            'category': category,
            'summary': news_title  # ê°„ë‹¨í•œ ê²½ìš°
        }
        
        caption_data = await generator.generate_viral_caption(news_data, "viral")
        hashtags = await generator.generate_trending_hashtags(news_data)
        
        # ì „ì²´ ìº¡ì…˜ ìƒì„±
        full_caption = f"{caption_data['caption']}\n\n{' '.join(hashtags[:25])}"
        
        # Instagram ë¦´ìŠ¤ ì—…ë¡œë“œ (ë¹„ë””ì˜¤ íŒŒì¼)
        instagram = get_instagram_service()
        
        # ë¹„ë””ì˜¤ íŒŒì¼ì„ public URLë¡œ ë³€í™˜ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” CDN ë“± ì‚¬ìš©)
        video_url = f"http://{HOST}:{PORT}/generated_videos/{os.path.basename(video_path)}"
        
        result = await instagram.post_reel_with_video(full_caption, video_url)
        
        # í¬ìŠ¤íŒ… ê¸°ë¡ ì €ì¥
        status = 'posted' if result.get('success') else 'failed'
        error_message = None if result.get('success') else str(result.get('error', ''))
        
        cursor.execute("""
            INSERT INTO news_posts 
            (news_id, reel_id, platform, post_type, post_id, caption, hashtags, media_urls, 
             posted_at, status, error_message, instagram_url)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            row[1],  # news_id
            reel_id,
            'instagram',
            'reel',
            result.get('post_id', ''),
            caption_data['caption'],
            json.dumps(hashtags),
            video_url,
            datetime.now().isoformat(),
            status,
            error_message,
            result.get('instagram_url', '')
        ))
        
        conn.commit()
        conn.close()
        
        return result
        
    except Exception as e:
        logger.error(f"ë¦´ìŠ¤ Instagram ì—…ë¡œë“œ ì˜¤ë¥˜: {e}")
        return {"success": False, "error": str(e)}

@app.post("/api/automation/full-reel-process")
async def full_reel_automation():
    """ì „ì²´ ë¦´ìŠ¤ ìë™í™” í”„ë¡œì„¸ìŠ¤"""
    try:
        results = {
            "scraped_news": 0,
            "created_reels": 0,
            "posted_reels": 0,
            "errors": []
        }
        
        # 1ë‹¨ê³„: ê³  ë°”ì´ëŸ´ ì ìˆ˜ ë‰´ìŠ¤ ìˆ˜ì§‘
        categories = list(NEWS_CATEGORIES.keys())
        scraper = get_news_scraper()
        producer = get_reels_producer()
        generator = get_content_generator()
        instagram = get_instagram_service()
        
        all_news = []
        
        for category in categories:
            try:
                logger.info(f"ğŸ“° {category} ì¹´í…Œê³ ë¦¬ ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘...")
                news_list = await scraper.scrape_latest_news(category, 3)
                
                if news_list:
                    # DBì— ì €ì¥
                    conn = sqlite3.connect("news_automation.db")
                    cursor = conn.cursor()
                    
                    for news in news_list:
                        cursor.execute("""
                            INSERT INTO news_articles 
                            (title, title_hash, link, summary, source, category, keywords, viral_score, scraped_at)
                            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                        """, (
                            news['title'],
                            news['title_hash'],
                            news['link'],
                            news['summary'],
                            news['source'],
                            news['category'],
                            json.dumps(news['keywords']),
                            news['viral_score'],
                            news['scraped_at']
                        ))
                        news['id'] = cursor.lastrowid
                        all_news.append(news)
                    
                    conn.commit()
                    conn.close()
                    
                    results["scraped_news"] += len(news_list)
                
            except Exception as e:
                results["errors"].append(f"{category} ìˆ˜ì§‘ ì˜¤ë¥˜: {str(e)}")
                continue
        
        # 2ë‹¨ê³„: ë°”ì´ëŸ´ ì ìˆ˜ ê¸°ì¤€ ìƒìœ„ ë‰´ìŠ¤ ì„ ë³„ (ìµœëŒ€ 3ê°œ)
        top_viral_news = sorted(all_news, key=lambda x: x['viral_score'], reverse=True)[:3]
        
        for news in top_viral_news:
            try:
                logger.info(f"ğŸ¬ ë‰´ìŠ¤ ID {news['id']} ë¦´ìŠ¤ ì œì‘ ì¤‘...")
                
                # ë¦´ìŠ¤ ì œì‘
                reel_result = await producer.create_news_reel(news, "trending", 15)
                
                if reel_result["success"]:
                    # DBì— ë¦´ìŠ¤ ì €ì¥
                    conn = sqlite3.connect("news_automation.db")
                    cursor = conn.cursor()
                    cursor.execute("""
                        INSERT INTO news_reels 
                        (news_id, video_path, style, duration, file_size_mb, created_at, status)
                        VALUES (?, ?, ?, ?, ?, ?, ?)
                    """, (
                        news['id'],
                        reel_result["video_path"],
                        "trending",
                        15,
                        reel_result["file_size_mb"],
                        datetime.now().isoformat(),
                        'created'
                    ))
                    
                    reel_id = cursor.lastrowid
                    conn.commit()
                    conn.close()
                    
                    results["created_reels"] += 1
                    
                    # 3ë‹¨ê³„: Instagram ì—…ë¡œë“œ
                    logger.info(f"ğŸ“± ë¦´ìŠ¤ ID {reel_id} Instagram ì—…ë¡œë“œ ì¤‘...")
                    
                    # ë°”ì´ëŸ´ ìº¡ì…˜ ìƒì„±
                    caption_data = await generator.generate_viral_caption(news, "viral")
                    hashtags = await generator.generate_trending_hashtags(news)
                    full_caption = f"{caption_data['caption']}\n\n{' '.join(hashtags[:25])}"
                    
                    # ë¹„ë””ì˜¤ URL ìƒì„±
                    video_url = f"http://{HOST}:{PORT}/generated_videos/{os.path.basename(reel_result['video_path'])}"
                    
                    # Instagram ì—…ë¡œë“œ
                    upload_result = await instagram.post_reel_with_video(full_caption, video_url)
                    
                    # ê²°ê³¼ ê¸°ë¡
                    conn = sqlite3.connect("news_automation.db")
                    cursor = conn.cursor()
                    
                    status = 'posted' if upload_result.get('success') else 'failed'
                    error_message = None if upload_result.get('success') else str(upload_result.get('error', ''))
                    
                    cursor.execute("""
                        INSERT INTO news_posts 
                        (news_id, reel_id, platform, post_type, post_id, caption, hashtags, 
                         media_urls, posted_at, status, error_message, instagram_url)
                        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    """, (
                        news['id'],
                        reel_id,
                        'instagram',
                        'reel',
                        upload_result.get('post_id', ''),
                        caption_data['caption'],
                        json.dumps(hashtags),
                        video_url,
                        datetime.now().isoformat(),
                        status,
                        error_message,
                        upload_result.get('instagram_url', '')
                    ))
                    
                    conn.commit()
                    conn.close()
                    
                    if upload_result.get('success'):
                        results["posted_reels"] += 1
                        logger.info(f"âœ… ë¦´ìŠ¤ ìë™í™” ì„±ê³µ: {news['title'][:50]}...")
                    else:
                        results["errors"].append(f"ë¦´ìŠ¤ ì—…ë¡œë“œ ì‹¤íŒ¨: {upload_result.get('message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
                    
                    # ì—…ë¡œë“œ ê°„ê²© (Instagram API ì œí•œ)
                    await asyncio.sleep(15)
                
                else:
                    results["errors"].append(f"ë¦´ìŠ¤ ì œì‘ ì‹¤íŒ¨: {reel_result.get('message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
                
            except Exception as e:
                results["errors"].append(f"ë‰´ìŠ¤ ID {news['id']} ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
                continue
        
        # ê²°ê³¼ ìš”ì•½
        success_rate = (results["posted_reels"] / max(results["created_reels"], 1)) * 100
        
        return {
            "success": True,
            "message": f"ë¦´ìŠ¤ ìë™í™” ì™„ë£Œ (ì„±ê³µë¥ : {success_rate:.1f}%)",
            "results": results,
            "top_viral_scores": [n['viral_score'] for n in top_viral_news]
        }
        
    except Exception as e:
        logger.error(f"ì „ì²´ ë¦´ìŠ¤ ìë™í™” ì˜¤ë¥˜: {e}")
        return {"success": False, "error": str(e)}

@app.get("/api/reels/recent")
async def get_recent_reels(limit: int = 10):
    """ìµœê·¼ ì œì‘ëœ ë¦´ìŠ¤ ëª©ë¡"""
    try:
        conn = sqlite3.connect("news_automation.db")
        cursor = conn.cursor()
        cursor.execute("""
            SELECT nr.*, na.title, na.category
            FROM news_reels nr
            JOIN news_articles na ON nr.news_id = na.id
            ORDER BY nr.created_at DESC 
            LIMIT ?
        """, (limit,))
        
        reels_list = []
        for row in cursor.fetchall():
            reels_list.append({
                'id': row[0],
                'news_id': row[1],
                'video_path': row[2],
                'video_url': f"/generated_videos/{os.path.basename(row[2])}",
                'style': row[4],
                'duration': row[5],
                'file_size_mb': row[6],
                'created_at': row[7],
                'status': row[8],
                'news_title': row[10],
                'category': row[11]
            })
        
        conn.close()
        
        return {
            "success": True,
            "reels": reels_list,
            "total": len(reels_list)
        }
        
    except Exception as e:
        logger.error(f"ë¦´ìŠ¤ ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return {"success": False, "error": str(e)}

@app.get("/api/news/trending")
async def get_trending_news(limit: int = 10):
    """ë°”ì´ëŸ´ ì ìˆ˜ ê¸°ì¤€ íŠ¸ë Œë”© ë‰´ìŠ¤"""
    try:
        conn = sqlite3.connect("news_automation.db")
        cursor = conn.cursor()
        cursor.execute("""
            SELECT id, title, link, summary, source, category, viral_score, scraped_at
            FROM news_articles 
            WHERE datetime(scraped_at) > datetime('now', '-1 days')
            ORDER BY viral_score DESC 
            LIMIT ?
        """, (limit,))
        
        news_list = []
        for row in cursor.fetchall():
            news_list.append({
                'id': row[0],
                'title': row[1],
                'link': row[2],
                'summary': row[3],
                'source': row[4],
                'category': row[5],
                'viral_score': row[6],
                'scraped_at': row[7]
            })
        
        conn.close()
        
        return {
            "success": True,
            "trending_news": news_list,
            "total": len(news_list)
        }
        
    except Exception as e:
        logger.error(f"íŠ¸ë Œë”© ë‰´ìŠ¤ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return {"success": False, "error": str(e)}

@app.get("/api/analytics/performance")
async def get_performance_analytics():
    """ì„±ê³¼ ë¶„ì„"""
    try:
        conn = sqlite3.connect("news_automation.db")
        cursor = conn.cursor()
        
        # ì „ì²´ í†µê³„
        cursor.execute("SELECT COUNT(*) FROM news_articles WHERE datetime(scraped_at) > datetime('now', '-7 days')")
        weekly_news = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM news_reels WHERE datetime(created_at) > datetime('now', '-7 days')")
        weekly_reels = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM news_posts WHERE status = 'posted' AND datetime(posted_at) > datetime('now', '-7 days')")
        weekly_posts = cursor.fetchone()[0]
        
        # ì¹´í…Œê³ ë¦¬ë³„ ì„±ê³¼
        cursor.execute("""
            SELECT category, COUNT(*), AVG(viral_score)
            FROM news_articles 
            WHERE datetime(scraped_at) > datetime('now', '-7 days')
            GROUP BY category
            ORDER BY AVG(viral_score) DESC
        """)
        category_performance = cursor.fetchall()
        
        # ì„±ê³µë¥  ê³„ì‚°
        success_rate = (weekly_posts / max(weekly_reels, 1)) * 100
        
        conn.close()
        
        return {
            "success": True,
            "analytics": {
                "weekly_stats": {
                    "news_collected": weekly_news,
                    "reels_created": weekly_reels,
                    "posts_published": weekly_posts,
                    "success_rate": round(success_rate, 1)
                },
                "category_performance": [
                    {
                        "category": row[0],
                        "news_count": row[1],
                        "avg_viral_score": round(row[2], 2)
                    } for row in category_performance
                ],
                "top_categories": [row[0] for row in category_performance[:3]]
            }
        }
        
    except Exception as e:
        logger.error(f"ì„±ê³¼ ë¶„ì„ ì˜¤ë¥˜: {e}")
        return {"success": False, "error": str(e)}

@app.get("/api/test-instagram")
async def test_instagram_api():
    """Instagram ì—°ê²° í…ŒìŠ¤íŠ¸ API"""
    try:
        instagram = get_instagram_service()
        result = await instagram.test_connection()
        return result
    except Exception as e:
        logger.error(f"Instagram í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
        return {"success": False, "error": str(e)}

@app.delete("/api/cleanup/old-files")
async def cleanup_old_files():
    """ì˜¤ë˜ëœ íŒŒì¼ ì •ë¦¬"""
    try:
        cleanup_count = 0
        
        # 7ì¼ ì´ìƒ ëœ ë¹„ë””ì˜¤ íŒŒì¼ ì‚­ì œ
        for filename in os.listdir(VIDEO_OUTPUT_DIR):
            file_path = os.path.join(VIDEO_OUTPUT_DIR, filename)
            if os.path.isfile(file_path):
                file_age = time.time() - os.path.getctime(file_path)
                if file_age > 7 * 24 * 3600:  # 7ì¼
                    os.remove(file_path)
                    cleanup_count += 1
        
        # 7ì¼ ì´ìƒ ëœ ì˜¤ë””ì˜¤ íŒŒì¼ ì‚­ì œ
        for filename in os.listdir(AUDIO_OUTPUT_DIR):
            file_path = os.path.join(AUDIO_OUTPUT_DIR, filename)
            if os.path.isfile(file_path):
                file_age = time.time() - os.path.getctime(file_path)
                if file_age > 7 * 24 * 3600:  # 7ì¼
                    os.remove(file_path)
                    cleanup_count += 1
        
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        for filename in os.listdir(TEMP_DIR):
            file_path = os.path.join(TEMP_DIR, filename)
            if os.path.isfile(file_path):
                os.remove(file_path)
                cleanup_count += 1
        
        return {
            "success": True,
            "message": f"{cleanup_count}ê°œì˜ íŒŒì¼ì´ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤",
            "cleaned_files": cleanup_count
        }
        
    except Exception as e:
        logger.error(f"íŒŒì¼ ì •ë¦¬ ì˜¤ë¥˜: {e}")
        return {"success": False, "error": str(e)}

@app.delete("/api/clear-data")
async def clear_data():
    """ë°ì´í„° ì´ˆê¸°í™”"""
    try:
        conn = sqlite3.connect("news_automation.db")
        cursor = conn.cursor()
        
        cursor.execute("DELETE FROM news_posts")
        cursor.execute("DELETE FROM generated_news_content")
        cursor.execute("DELETE FROM news_reels")
        cursor.execute("DELETE FROM news_articles")
        
        conn.commit()
        conn.close()
        
        return {"success": True, "message": "ëª¨ë“  ë°ì´í„°ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤"}
        
    except Exception as e:
        logger.error(f"ë°ì´í„° ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
        return {"success": False, "error": str(e)}

@app.get("/health")
async def enhanced_health_check():
    """í–¥ìƒëœ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸"""
    try:
        conn = sqlite3.connect("news_automation.db")
        cursor = conn.cursor()
        
        cursor.execute("SELECT COUNT(*) FROM news_articles")
        total_news = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM news_reels")
        total_reels = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM news_posts WHERE status = 'posted'")
        posted_content = cursor.fetchone()[0]
        
        cursor.execute("SELECT AVG(viral_score) FROM news_articles WHERE datetime(scraped_at) > datetime('now', '-1 days')")
        avg_viral_score = cursor.fetchone()[0] or 0
        
        conn.close()
        
        generator = get_content_generator()
        
        # ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ í™•ì¸
        video_dir_size = 0
        try:
            video_dir_size = sum(os.path.getsize(os.path.join(VIDEO_OUTPUT_DIR, f)) 
                               for f in os.listdir(VIDEO_OUTPUT_DIR) if os.path.isfile(os.path.join(VIDEO_OUTPUT_DIR, f)))
        except:
            pass
        video_dir_size_mb = video_dir_size / (1024 * 1024)
        
        return {
            "status": "healthy",
            "database": "connected",
            "services": {
                "news_scraper": "active",
                "reels_producer": "active", 
                "content_generator": "active",
                "openai_available": generator.openai_client is not None
            },
            "statistics": {
                "total_news": total_news,
                "total_reels": total_reels,
                "posted_content": posted_content,
                "avg_viral_score": round(avg_viral_score, 2),
                "video_storage_mb": round(video_dir_size_mb, 1)
            },
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        return {
            "status": "error",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

if __name__ == "__main__":
    print("ğŸš€ ADVANCED NEWS AUTOMATION - AI ë‰´ìŠ¤ & ë¦´ìŠ¤ ìë™í™” í”Œë«í¼")
    print(f"ğŸ“± API ì„œë²„: http://{HOST}:{PORT}")
    print(f"ğŸ“Š ëŒ€ì‹œë³´ë“œ: http://{HOST}:{PORT}/dashboard")
    print(f"ğŸ“š API ë¬¸ì„œ: http://{HOST}:{PORT}/docs")
    print("=" * 80)
    print("ğŸ¯ ìƒˆë¡œìš´ ê¸°ëŠ¥:")
    print("  â€¢ âœ… ë‹¤ì¤‘ ì†ŒìŠ¤ ë‰´ìŠ¤ í¬ë¡¤ë§ (Google News)")
    print("  â€¢ âœ… AI ë°”ì´ëŸ´ ìº¡ì…˜ ìƒì„±")
    print("  â€¢ âœ… ìë™ ë¦´ìŠ¤ ì œì‘ (TTS + ë¹„ì£¼ì–¼)")
    print("  â€¢ âœ… Instagram ë¦´ìŠ¤ ìë™ ì—…ë¡œë“œ")
    print("  â€¢ âœ… ë°”ì´ëŸ´ ì ìˆ˜ ê¸°ë°˜ ìš°ì„ ìˆœìœ„")
    print("  â€¢ âœ… ì„±ê³¼ ë¶„ì„ ë° ëª¨ë‹ˆí„°ë§")
    print("=" * 80)
    
    # ìˆ˜ì •ëœ ì½”ë“œ:
if __name__ == "__main__":
    import uvicorn
    import os
    
    port = int(os.environ.get("PORT", 8000))
    uvicorn.run("clean_news_automation:app", host="0.0.0.0", port=port, reload=False)